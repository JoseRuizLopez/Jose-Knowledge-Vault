[
  {"id":"albelwiFrameworkDesigningArchitectures2017","abstract":"Recent advances in Convolutional Neural Networks (CNNs) have obtained promising results in difficult deep learning tasks. However, the success of a CNN depends on finding an architecture to fit a given problem. A hand-crafted architecture is a challenging, time-consuming process that requires expert knowledge and effort, due to a large number of architectural design choices. In this article, we present an efficient framework that automatically designs a high-performing CNN architecture for a given problem. In this framework, we introduce a new optimization objective function that combines the error rate and the information learnt by a set of feature maps using deconvolutional networks (deconvnet). The new objective function allows the hyperparameters of the CNN architecture to be optimized in a way that enhances the performance by guiding the CNN through better visualization of learnt features via deconvnet. The actual optimization of the objective function is carried out via the Nelder-Mead Method (NMM). Further, our new objective function results in much faster convergence towards a better architecture. The proposed framework has the ability to explore a CNN architecture’s numerous design choices in an efficient way and also allows effective, distributed execution and synchronization via web services. Empirically, we demonstrate that the CNN architecture designed with our approach outperforms several existing approaches in terms of its error rate. Our results are also competitive with state-of-the-art results on the MNIST dataset and perform reasonably against the state-of-the-art results on CIFAR-10 and CIFAR-100 datasets. Our approach has a significant role in increasing the depth, reducing the size of strides, and constraining some convolutional layers not followed by pooling layers in order to find a CNN architecture that produces a high recognition performance.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Albelwi","given":"Saleh"},{"family":"Mahmood","given":"Ausif"}],"citation-key":"albelwiFrameworkDesigningArchitectures2017","container-title":"Entropy","DOI":"10.3390/e19060242","ISSN":"1099-4300","issue":"6","issued":{"date-parts":[["2017",6]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"6","page":"242","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"A Framework for Designing the Architectures of Deep Convolutional Neural Networks","type":"article-journal","URL":"https://www.mdpi.com/1099-4300/19/6/242","volume":"19"},
  {"id":"alnuaimHumanComputerInteractionHand2022","abstract":"Sign language is the native language of deaf people, which they use in their daily life, and it facilitates the communication process between deaf people. The problem faced by deaf people is targeted using sign language technique. Sign language refers to the use of the arms and hands to communicate, particularly among those who are deaf. This varies depending on the person and the location from which they come. As a result, there is no standardization about the sign language to be used; for example, American, British, Chinese, and Arab sign languages are all distinct. Here, in this study we trained a model, which will be able to classify the Arabic sign language, which consists of 32 Arabic alphabet sign classes. In images, sign language is detected through the pose of the hand. In this study, we proposed a framework, which consists of two CNN models, and each of them is individually trained on the training set. The final predictions of the two models were ensembled to achieve higher results. The dataset used in this study is released in 2019 and is called as ArSL2018. It is launched at the Prince Mohammad Bin Fahd University, Al Khobar, Saudi Arabia. The main contribution in this study is resizing the images to 64 ∗ 64 pixels, converting from grayscale images to three-channel images, and then applying the median filter to the images, which acts as lowpass filtering in order to smooth the images and reduce noise and to make the model more robust to avoid overfitting. Then, the preprocessed image is fed into two different models, which are ResNet50 and MobileNetV2. ResNet50 and MobileNetV2 architectures were implemented together. The results we achieved on the test set for the whole data are with an accuracy of about 97% after applying many preprocessing techniques and different hyperparameters for each model, and also different data augmentation techniques.","author":[{"family":"Alnuaim","given":"Abeer"},{"family":"Zakariah","given":"Mohammed"},{"family":"Hatamleh","given":"Wesam Atef"},{"family":"Tarazi","given":"Hussam"},{"family":"Tripathi","given":"Vikas"},{"family":"Amoatey","given":"Enoch Tetteh"}],"citation-key":"alnuaimHumanComputerInteractionHand2022","container-title":"Computational Intelligence and Neuroscience","DOI":"10.1155/2022/8777355","ISSN":"1687-5273","issue":"1","issued":{"date-parts":[["2022"]]},"language":"en","page":"8777355","source":"Wiley Online Library","title":"Human-Computer Interaction with Hand Gesture Recognition Using ResNet and MobileNet","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/8777355","volume":"2022"},
  {"id":"amodeoOGSGGOntologyGuidedScene2022","abstract":"Scene graph generation from images is a task of great interest to applications such as robotics, because graphs are the main way to represent knowledge about the world and regulate human-robot interactions in tasks such as Visual Question Answering (VQA). Unfortunately, its corresponding area of machine learning is still relatively in its infancy, and the solutions currently offered do not specialize well in concrete usage scenarios. Specifically, they do not take existing \"expert\" knowledge about the domain world into account; and that might indeed be necessary in order to provide the level of reliability demanded by the use case scenarios. In this paper, we propose an initial approximation to a framework called Ontology-Guided Scene Graph Generation (OG-SGG), that can improve the performance of an existing machine learning based scene graph generator using prior knowledge supplied in the form of an ontology (specifically, using the axioms defined within); and we present results evaluated on a specific scenario founded in telepresence robotics. These results show quantitative and qualitative improvements in the generated scene graphs.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Amodeo","given":"Fernando"},{"family":"Caballero","given":"Fernando"},{"family":"Díaz-Rodríguez","given":"Natalia"},{"family":"Merino","given":"Luis"}],"citation-key":"amodeoOGSGGOntologyGuidedScene2022","container-title":"IEEE Access","container-title-short":"IEEE Access","DOI":"10.1109/ACCESS.2022.3230590","ISSN":"2169-3536","issued":{"date-parts":[["2022"]]},"page":"132564-132583","source":"arXiv.org","title":"OG-SGG: Ontology-Guided Scene Graph Generation. A Case Study in Transfer Learning for Telepresence Robotics","title-short":"OG-SGG","type":"article-journal","URL":"http://arxiv.org/abs/2202.10201","volume":"10"},
  {"id":"arazziSecureFederatedData2025","abstract":"Dataset Distillation (DD) is a powerful technique for reducing large datasets into compact, representative synthetic datasets, accelerating Machine Learning training. However, traditional DD methods operate in a centralized manner, which poses significant privacy threats and reduces its applicability. To mitigate these risks, we propose a Secure Federated Data Distillation (SFDD) framework to decentralize the distillation process while preserving privacy. Unlike existing Federated Distillation techniques that focus on training global models with distilled knowledge, our approach aims to produce a distilled dataset without exposing local contributions. We leverage the gradient-matching-based distillation method, adapting it for a distributed setting where clients contribute to the distillation process without sharing raw data. The central aggregator iteratively refines a synthetic dataset by integrating client-side updates while ensuring data confidentiality. To make our approach resilient to inference attacks perpetrated by the server that could exploit gradient updates to reconstruct private data, we create an optimized Local Differential Privacy approach, called LDPO-RLD. Furthermore, we assess the framework's resilience against malicious clients executing backdoor attacks (such as Doorping) and demonstrate robustness under the assumption of a sufficient number of participating clients. Our experimental results demonstrate the effectiveness of SFDD and that the proposed defense concretely mitigates the identified vulnerabilities, with minimal impact on the performance of the distilled dataset. By addressing the interplay between privacy and federation in dataset distillation, this work advances the field of privacy-preserving Machine Learning making our SFDD framework a viable solution for sensitive data-sharing applications.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Arazzi","given":"Marco"},{"family":"Cihangiroglu","given":"Mert"},{"family":"Nicolazzo","given":"Serena"},{"family":"Nocera","given":"Antonino"}],"citation-key":"arazziSecureFederatedData2025","DOI":"10.48550/arXiv.2502.13728","issued":{"date-parts":[["2025",3,6]]},"number":"arXiv:2502.13728","publisher":"arXiv","source":"arXiv.org","title":"Secure Federated Data Distillation","type":"article","URL":"http://arxiv.org/abs/2502.13728"},
  {"id":"BIGBenchNewBenchmark2024","abstract":"Dive into BIG-Bench, the comprehensive benchmark designed for evaluating the capabilities and biases of large language models, and discover its significance ...","accessed":{"date-parts":[["2025",10,8]]},"citation-key":"BIGBenchNewBenchmark2024","container-title":"Deepgram","issued":{"date-parts":[["2024",6,27]]},"language":"en","title":"BIG-Bench: The New Benchmark for Language Models","title-short":"BIG-Bench","type":"webpage","URL":"https://deepgram.com/learn/big-bench-llm-benchmark-guide"},
  {"id":"bortolottiNeuroSymbolicBenchmarkSuite2024","abstract":"The advent of powerful neural classifiers has increased interest in problems that require both learning and reasoning. These problems are critical for understanding important properties of models, such as trustworthiness, generalization, interpretability, and compliance to safety and structural constraints. However, recent research observed that tasks requiring both learning and reasoning on background knowledge often suffer from reasoning shortcuts (RSs): predictors can solve the downstream reasoning task without associating the correct concepts to the high-dimensional data. To address this issue, we introduce rsbench, a comprehensive benchmark suite designed to systematically evaluate the impact of RSs on models by providing easy access to highly customizable tasks affected by RSs. Furthermore, rsbench implements common metrics for evaluating concept quality and introduces novel formal verification procedures for assessing the presence of RSs in learning tasks. Using rsbench, we highlight that obtaining high quality concepts in both purely neural and neuro-symbolic models is a far-from-solved problem. rsbench is available at: https://unitn-sml.github.io/rsbench.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Bortolotti","given":"Samuele"},{"family":"Marconato","given":"Emanuele"},{"family":"Carraro","given":"Tommaso"},{"family":"Morettin","given":"Paolo"},{"family":"Krieken","given":"Emile","dropping-particle":"van"},{"family":"Vergari","given":"Antonio"},{"family":"Teso","given":"Stefano"},{"family":"Passerini","given":"Andrea"}],"citation-key":"bortolottiNeuroSymbolicBenchmarkSuite2024","DOI":"10.48550/arXiv.2406.10368","issued":{"date-parts":[["2024",10,29]]},"number":"arXiv:2406.10368","publisher":"arXiv","source":"arXiv.org","title":"A Neuro-Symbolic Benchmark Suite for Concept Quality and Reasoning Shortcuts","type":"article","URL":"http://arxiv.org/abs/2406.10368"},
  {"id":"chaconProGit2014","abstract":"Pro Git (Second Edition) is your fully-updated guide to Git and its usage in the modern world. Git has come a long way since it was first developed by Linus Torvalds for Linux kernel development. It has taken the open source world by storm since its inception in 2005, and this book teaches you how to use it like a pro. Effective and well-implemented version control is a necessity for successful web projects, whether large or small. With this book you’ll learn how to master the world of distributed version workflow, use the distributed features of Git to the full, and extend Git to meet your every need. Written by Git pros Scott Chacon and Ben Straub, Pro Git (Second Edition) builds on the hugely successful first edition, and is now fully updated for Git version 2.0, as well as including an indispensable chapter on GitHub. It’s the best book for all your Git needs.","author":[{"family":"Chacon","given":"Scott"},{"family":"Straub","given":"Ben"}],"citation-key":"chaconProGit2014","DOI":"10.1007/978-1-4842-0076-6","edition":"Second","event-place":"New York","ISBN":"978-1-4842-0076-6","issued":{"date-parts":[["2014"]]},"language":"English","publisher":"Apress","publisher-place":"New York","title":"Pro Git","type":"book","URL":"https://git-scm.com/book/en/v2"},
  {"id":"chenClusteringBasedSubsetSelection2021","abstract":"Subset selection is an important component in evolutionary multiobjective optimization (EMO) algorithms. Clustering, as a classic method to group similar data points together, has been used for subset selection in some fields. However, clustering-based methods have not been evaluated in the context of subset selection from solution sets obtained by EMO algorithms. In this paper, we first review some classic clustering algorithms. We also point out that another popular subset selection method, i.e., inverted generational distance (IGD)-based subset selection, can be viewed as clustering. Then, we perform a comprehensive experimental study to evaluate the performance of various clustering algorithms in different scenarios. Experimental results are analyzed in detail, and some suggestions about the use of clustering algorithms for subset selection are derived. Additionally, we demonstrate that decision maker's preference can be introduced to clustering-based subset selection.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Chen","given":"Weiyu"},{"family":"Ishibuchi","given":"Hisao"},{"family":"Shang","given":"Ke"}],"citation-key":"chenClusteringBasedSubsetSelection2021","DOI":"10.48550/arXiv.2108.08453","issued":{"date-parts":[["2021",8,29]]},"number":"arXiv:2108.08453","publisher":"arXiv","source":"arXiv.org","title":"Clustering-Based Subset Selection in Evolutionary Multiobjective Optimization","type":"article","URL":"http://arxiv.org/abs/2108.08453"},
  {"id":"choiNeuroSymbolicVideoUnderstanding2025","abstract":"The unprecedented surge in video data production in recent years necessitates efficient tools to extract meaningful frames from videos for downstream tasks. Long-term temporal reasoning is a key desideratum for frame retrieval systems. While state-of-the-art foundation models, like VideoLLaMA and ViCLIP, are proficient in short-term semantic understanding, they surprisingly fail at long-term reasoning across frames. A key reason for this failure is that they intertwine per-frame perception and temporal reasoning into a single deep network. Hence, decoupling but co-designing semantic understanding and temporal reasoning is essential for efficient scene identification. We propose a system that leverages vision-language models for semantic understanding of individual frames but effectively reasons about the long-term evolution of events using state machines and temporal logic (TL) formulae that inherently capture memory. Our TL-based reasoning improves the F1 score of complex event identification by 9-15% compared to benchmarks that use GPT4 for reasoning on state-of-the-art self-driving datasets such as Waymo and NuScenes.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Choi","given":"Minkyu"},{"family":"Goel","given":"Harsh"},{"family":"Omama","given":"Mohammad"},{"family":"Yang","given":"Yunhao"},{"family":"Shah","given":"Sahil"},{"family":"Chinchali","given":"Sandeep"}],"citation-key":"choiNeuroSymbolicVideoUnderstanding2025","DOI":"10.1007/978-3-031-73229-4_13","issued":{"date-parts":[["2025"]]},"page":"220-236","source":"arXiv.org","title":"Towards Neuro-Symbolic Video Understanding","type":"chapter","URL":"http://arxiv.org/abs/2403.11021","volume":"15136"},
  {"id":"CIFAR10Dataset","accessed":{"date-parts":[["2025",6,12]]},"citation-key":"CIFAR10Dataset","title":"CIFAR-10 dataset","type":"webpage","URL":"https://www.cs.toronto.edu/~kriz/cifar.html"},
  {"id":"Cifar10PyTorch","accessed":{"date-parts":[["2025",6,12]]},"citation-key":"Cifar10PyTorch","title":"Cifar10-PyTorch","type":"webpage","URL":"https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"},
  {"id":"CleanedArtImages","abstract":"Dataset with about 9000 images containing 5 types of arts","accessed":{"date-parts":[["2025",2,24]]},"citation-key":"CleanedArtImages","language":"en","title":"(Cleaned) Art Images: Drawing/Painting/Sculptures/Engravings","title-short":"Art Images","type":"webpage","URL":"https://www.kaggle.com/datasets/moosecat/art-images-drawings-painting-sculpture-engraving"},
  {"id":"coleloughNeuroSymbolicAI20242025","abstract":"Background: The field of Artificial Intelligence has undergone cyclical periods of growth and decline, known as AI summers and winters. Currently, we are in the third AI summer, characterized by significant advancements and commercialization, particularly in the integration of Symbolic AI and Sub-Symbolic AI, leading to the emergence of Neuro-Symbolic AI. Methods: The review followed the PRISMA methodology, utilizing databases such as IEEE Explore, Google Scholar, arXiv, ACM, and SpringerLink. The inclusion criteria targeted peer-reviewed papers published between 2020 and 2024. Papers were screened for relevance to Neuro-Symbolic AI, with further inclusion based on the availability of associated codebases to ensure reproducibility. Results: From an initial pool of 1,428 papers, 167 met the inclusion criteria and were analyzed in detail. The majority of research efforts are concentrated in the areas of learning and inference (63%), logic and reasoning (35%), and knowledge representation (44%). Explainability and trustworthiness are less represented (28%), with Meta-Cognition being the least explored area (5%). The review identifies significant interdisciplinary opportunities, particularly in integrating explainability and trustworthiness with other research areas. Conclusion: Neuro-Symbolic AI research has seen rapid growth since 2020, with concentrated efforts in learning and inference. Significant gaps remain in explainability, trustworthiness, and Meta-Cognition. Addressing these gaps through interdisciplinary research will be crucial for advancing the field towards more intelligent, reliable, and context-aware AI systems.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Colelough","given":"Brandon C."},{"family":"Regli","given":"William"}],"citation-key":"coleloughNeuroSymbolicAI20242025","DOI":"10.48550/arXiv.2501.05435","issued":{"date-parts":[["2025",4,5]]},"number":"arXiv:2501.05435","publisher":"arXiv","source":"arXiv.org","title":"Neuro-Symbolic AI in 2024: A Systematic Review","title-short":"Neuro-Symbolic AI in 2024","type":"article","URL":"http://arxiv.org/abs/2501.05435"},
  {"id":"CondaDocumentation","accessed":{"date-parts":[["2025",2,24]]},"citation-key":"CondaDocumentation","title":"Conda Documentation","type":"webpage","URL":"https://docs.conda.io/en/latest/"},
  {"id":"CreationVirtualEnvironments","abstract":"Código fuente: Lib/venv/ El módulo venv admite la creación de «entornos virtuales» ligeros, cada uno con su propio conjunto independiente de paquetes de Python instalados en sus directorios site. S...","accessed":{"date-parts":[["2025",2,24]]},"citation-key":"CreationVirtualEnvironments","container-title":"Python documentation","language":"es","title":"Creation of virtual environments","type":"webpage","URL":"https://docs.python.org/3/library/venv.html"},
  {"id":"CuBLASDeterministicAlgorithms","accessed":{"date-parts":[["2025",2,24]]},"citation-key":"CuBLASDeterministicAlgorithms","title":"cuBLAS Deterministic Algorithms","type":"webpage","URL":"https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility"},
  {"id":"delongNeurosymbolicAIReasoning2025","abstract":"Neurosymbolic AI is an increasingly active area of research that combines symbolic reasoning methods with deep learning to leverage their complementary benefits. As knowledge graphs are becoming a popular way to represent heterogeneous and multi-relational data, methods for reasoning on graph structures have attempted to follow this neurosymbolic paradigm. Traditionally, such approaches have utilized either rule-based inference or generated representative numerical embeddings from which patterns could be extracted. However, several recent studies have attempted to bridge this dichotomy to generate models that facilitate interpretability, maintain competitive performance, and integrate expert knowledge. Therefore, we survey methods that perform neurosymbolic reasoning tasks on knowledge graphs and propose a novel taxonomy by which we can classify them. Specifically, we propose three major categories: (1) logically-informed embedding approaches, (2) embedding approaches with logical constraints, and (3) rule learning approaches. Alongside the taxonomy, we provide a tabular overview of the approaches and links to their source code, if available, for more direct comparison. Finally, we discuss the unique characteristics and limitations of these methods, then propose several prospective directions toward which this field of research could evolve.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"DeLong","given":"Lauren Nicole"},{"family":"Mir","given":"Ramon Fernández"},{"family":"Fleuriot","given":"Jacques D."}],"citation-key":"delongNeurosymbolicAIReasoning2025","container-title":"IEEE Transactions on Neural Networks and Learning Systems","container-title-short":"IEEE Trans. Neural Netw. Learning Syst.","DOI":"10.1109/TNNLS.2024.3420218","ISSN":"2162-237X, 2162-2388","issue":"5","issued":{"date-parts":[["2025",5]]},"page":"7822-7842","source":"arXiv.org","title":"Neurosymbolic AI for Reasoning over Knowledge Graphs: A Survey","title-short":"Neurosymbolic AI for Reasoning over Knowledge Graphs","type":"article-journal","URL":"http://arxiv.org/abs/2302.07200","volume":"36"},
  {"id":"derracSurveyEvolutionaryInstance2012","abstract":"The use of Evolutionary Algorithms to perform data reduction tasks has become an effective approach to improve the performance of data mining algorithms. Many proposals in the literature have shown that Evolutionary Algorithms obtain excellent results in their application as Instance Selection and I...","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Derrac","given":"Joaquín"},{"family":"García","given":"Salvador"},{"family":"Herrera","given":"Francisco"}],"citation-key":"derracSurveyEvolutionaryInstance2012","container-title":"Modeling, Analysis, and Applications in Metaheuristic Computing: Advancements and Trends","DOI":"10.4018/978-1-4666-0270-0.ch014","ISBN":"978-1-4666-0270-0","issued":{"date-parts":[["2012"]]},"language":"en","license":"Access limited to members","page":"233-266","publisher":"IGI Global Scientific Publishing","source":"www.igi-global.com","title":"A Survey on Evolutionary Instance Selection and Generation","type":"chapter","URL":"https://www.igi-global.com/gateway/chapter/63814"},
  {"id":"dimasiSceneGraphGeneration2023","abstract":"The 2022 study on traffic fatalities in Italy by the Italian National Institute of Statistics (ISTAT) reports 454 daily fatalities and 561 injuries, primarily due to distractions. Then, the success of Autonomous Driving depends on intelligent perception systems to enhance road safety, with vision systems playing a critical role throughout its history.  In the field of Computer Vision, Deep Learning has gained mainstream acceptance for its ability to model complex problems like Object Detection and Instance Segmentation. More recently, Scene Graph Generation has emerged as a novel paradigm, where scenes are depicted as graphs with objects as nodes and their relationships as edges. This area has seen substantial research,  but only a limited fraction of it pertains to autonomous driving applications and most of it focuses on specific traffic scenarios, limiting diversity.  A comprehensive effort for incorporating all relevant objects in traffic scenarios resulted in the creation of the Traffic Genome dataset. However, it suffers from bias due to uneven relationship frequency, which can lead to the misclassification of rare events. This thesis addresses this issue by infusing prior knowledge into scene graph generation using neuro-symbolic approaches.  Relational Transformer network is used as baseline, due to its state-of-arts results in the one-stage approaches.  Two methodologies for knowledge injection are adopted. The first involves external knowledge injection through Knowledge Graph Embedding(KGE) techniques using PandaSet, an autonomous driving dataset released by Hesai and Scale AI, as the foundational knowledge base due to its rich multi-modal information. The second approach utilizes the Logic Tensor Network(LTN) for constraint satisfaction, employing axioms as constraints during training.  Results indicate that both methods improve performance, with the choice depending on the trade-off between deployment speed and accuracy: KGE methods are faster to develop but limited by available relationships in the knowledge base, while LTN potentially can outperform them but requires more time to design optimal axioms based on domain expertise.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Dimasi","given":"Paolo Emmanuel Ilario"}],"citation-key":"dimasiSceneGraphGeneration2023","genre":"laurea","issued":{"date-parts":[["2023",12,15]]},"language":"it","license":"cc_by_nc_nd","number-of-pages":"92","publisher":"Politecnico di Torino","source":"webthesis.biblio.polito.it","title":"Scene Graph Generation in Autonomous Driving: a Neuro-symbolic approach","title-short":"Scene Graph Generation in Autonomous Driving","type":"thesis","URL":"https://webthesis.biblio.polito.it/29354/"},
  {"id":"dongMemeticAlgorithmEvolving2020","author":[{"family":"Dong","given":"Junwei"},{"family":"Zhang","given":"Liangjie"},{"family":"Hou","given":"Boyu"},{"family":"Feng","given":"Liang"}],"citation-key":"dongMemeticAlgorithmEvolving2020","DOI":"10.1109/SSCI47803.2020.9308162","issued":{"date-parts":[["2020",12]]},"page":"2663-2669","title":"A Memetic Algorithm for Evolving Deep Convolutional Neural Network in Image Classification","type":"paper-conference"},
  {"id":"EnhancingCollaborationProjectbased","abstract":"The force driving a project-based organization (PBO) is the performance and completion of project tasks. Because of this, PBOs rely on collaborative relationships and innovative technologies to accomplish their goals. This paper examines a framework that could help PBOs improve their collaborations and a multi-level strategy that may help PBOs use innovation technologies more effectively. In doing so, it defines the concept of collaboration and overviews the field's literature on collaboration and on using technology to improve inter-organization collaboration; it identifies the barriers to collaboration that PBOs often face and the organizational typologies common to PBOs. It looks at how collaborative information technologies can support PBOs, noting how--via a proposed framework--these functionalities relate to the process of managing projects. It then outlines the proposed strategy, explaining the concept of e-collaboration and its relationship to collaboration in PBOs. It discusses the process of impleme","accessed":{"date-parts":[["2025",5,11]]},"citation-key":"EnhancingCollaborationProjectbased","language":"en","title":"Enhancing collaboration in project-based organizations with IT","type":"webpage","URL":"https://www.pmi.org/learning/library/enhancing-collaboration-project-based-organizations-7141"},
  {"id":"euAIAct2024","author":[{"literal":"European Parliament and Council"}],"citation-key":"euAIAct2024","issued":{"date-parts":[["2024"]]},"title":"Article 10: Data and Data Governance, EU Artificial Intelligence Act","type":"document","URL":"https://artificialintelligenceact.eu/article/10/"},
  {"id":"FB15kDatasetDGL25","accessed":{"date-parts":[["2025",10,8]]},"citation-key":"FB15kDatasetDGL25","title":"FB15kDataset — DGL 2.5 documentation","type":"webpage","URL":"https://www.dgl.ai/dgl_docs/generated/dgl.data.FB15kDataset.html"},
  {"id":"garciaMemeticAlgorithmEvolutionary2008","abstract":"Prototype selection problem consists of reducing the size of databases by removing samples that are considered noisy or not influential on nearest neighbour classification tasks. Evolutionary algorithms have been used recently for prototype selection showing good results. However, due to the complexity of this problem when the size of the databases increases, the behaviour of evolutionary algorithms could deteriorate considerably because of a lack of convergence. This additional problem is known as the scaling up problem. Memetic algorithms are approaches for heuristic searches in optimization problems that combine a population-based algorithm with a local search. In this paper, we propose a model of memetic algorithm that incorporates an ad hoc local search specifically designed for optimizing the properties of prototype selection problem with the aim of tackling the scaling up problem. In order to check its performance, we have carried out an empirical study including a comparison between our proposal and previous evolutionary and non-evolutionary approaches studied in the literature. The results have been contrasted with the use of non-parametric statistical procedures and show that our approach outperforms previously studied methods, especially when the database scales up.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"García","given":"Salvador"},{"family":"Cano","given":"José Ramón"},{"family":"Herrera","given":"Francisco"}],"citation-key":"garciaMemeticAlgorithmEvolutionary2008","container-title":"Pattern Recognition","container-title-short":"Pattern Recognition","DOI":"10.1016/j.patcog.2008.02.006","ISSN":"0031-3203","issue":"8","issued":{"date-parts":[["2008",8,1]]},"page":"2693-2709","source":"ScienceDirect","title":"A memetic algorithm for evolutionary prototype selection: A scaling up approach","title-short":"A memetic algorithm for evolutionary prototype selection","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0031320308000770","volume":"41"},
  {"id":"GitHubcomDocumentacionAyuda","abstract":"Comenzar, solucionar problemas y aprovechar GitHub. Documentación para nuevos usuarios, desarrolladores, administradores y todos los productos de GitHub.","accessed":{"date-parts":[["2025",4,11]]},"citation-key":"GitHubcomDocumentacionAyuda","container-title":"GitHub Docs","language":"es","title":"GitHub.com Documentación de ayuda","type":"webpage","URL":"https://docs-internal.github.com/es"},
  {"id":"goldbergGeneticAlgorithmsSearch1989","author":[{"family":"Goldberg","given":"D.E."}],"citation-key":"goldbergGeneticAlgorithmsSearch1989","collection-title":"Addison Wesley series in artificial intelligence","ISBN":"978-0-201-15767-3","issued":{"date-parts":[["1989"]]},"publisher":"Addison-Wesley","title":"Genetic Algorithms in Search, Optimization, and Machine Learning","type":"book","URL":"https://books.google.es/books?id=2IIJAAAACAAJ"},
  {"id":"goodfellowDeepLearning2016","author":[{"family":"Goodfellow","given":"Ian"},{"family":"Bengio","given":"Yoshua"},{"family":"Courville","given":"Aaron"}],"citation-key":"goodfellowDeepLearning2016","issued":{"date-parts":[["2016"]]},"publisher":"MIT Press","title":"Deep Learning","type":"book"},
  {"id":"hartCondensedNearestNeighbor1968","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Hart","given":"P."}],"citation-key":"hartCondensedNearestNeighbor1968","container-title":"IEEE Transactions on Information Theory","DOI":"10.1109/TIT.1968.1054155","ISSN":"1557-9654","issue":"3","issued":{"date-parts":[["1968",5]]},"page":"515-516","source":"IEEE Xplore","title":"The condensed nearest neighbor rule (Corresp.)","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/1054155","volume":"14"},
  {"id":"heDeepResidualLearning2016","author":[{"family":"He","given":"Kaiming"},{"family":"Zhang","given":"Xiangyu"},{"family":"Ren","given":"Shaoqing"},{"family":"Sun","given":"Jian"}],"citation-key":"heDeepResidualLearning2016","container-title":"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","DOI":"10.1109/CVPR.2016.90","issued":{"date-parts":[["2016"]]},"page":"770-778","title":"Deep Residual Learning for Image Recognition","type":"paper-conference"},
  {"id":"hintonDistillingKnowledgeNeural2015","abstract":"A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Hinton","given":"Geoffrey"},{"family":"Vinyals","given":"Oriol"},{"family":"Dean","given":"Jeff"}],"citation-key":"hintonDistillingKnowledgeNeural2015","DOI":"10.48550/arXiv.1503.02531","issued":{"date-parts":[["2015",3,9]]},"number":"arXiv:1503.02531","publisher":"arXiv","source":"arXiv.org","title":"Distilling the Knowledge in a Neural Network","type":"article","URL":"http://arxiv.org/abs/1503.02531"},
  {"id":"HolisticEvaluationLanguage","accessed":{"date-parts":[["2025",10,8]]},"citation-key":"HolisticEvaluationLanguage","title":"Holistic Evaluation of Language Models (HELM)","type":"webpage","URL":"https://crfm.stanford.edu/helm/"},
  {"id":"hollandAdaptationNaturalArtificial1975","author":[{"family":"Holland","given":"J.H."}],"citation-key":"hollandAdaptationNaturalArtificial1975","ISBN":"978-0-472-08460-9","issued":{"date-parts":[["1975"]]},"publisher":"University of Michigan Press","title":"Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence","type":"book","URL":"https://books.google.es/books?id=YE5RAAAAMAAJ"},
  {"id":"howardMobileNetsEfficientConvolutional2017","abstract":"We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.","author":[{"family":"Howard","given":"Andrew G."},{"family":"Zhu","given":"Menglong"},{"family":"Chen","given":"Bo"},{"family":"Kalenichenko","given":"Dmitry"},{"family":"Wang","given":"Weijun"},{"family":"Weyand","given":"Tobias"},{"family":"Andreetto","given":"Marco"},{"family":"Adam","given":"Hartwig"}],"citation-key":"howardMobileNetsEfficientConvolutional2017","DOI":"10.48550/arXiv.1704.04861","issued":{"date-parts":[["2017",4,17]]},"number":"arXiv:1704.04861","publisher":"arXiv","source":"arXiv.org","title":"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications","title-short":"MobileNets","type":"article","URL":"http://arxiv.org/abs/1704.04861"},
  {"id":"jiaCertifiedRobustnessNearest2021","abstract":"Data poisoning attacks and backdoor attacks aim to corrupt a machine learning classifier via modifying, adding, and/or removing some carefully selected training examples, such that the corrupted classifier makes incorrect predictions as the attacker desires. The key idea of state-of-the-art certified defenses against data poisoning attacks and backdoor attacks is to create a majority vote mechanism to predict the label of a testing example. Moreover, each voter is a base classifier trained on a subset of the training dataset. Classical simple learning algorithms such as k nearest neighbors (kNN) and radius nearest neighbors (rNN) have intrinsic majority vote mechanisms. In this work, we show that the intrinsic majority vote mechanisms in kNN and rNN already provide certified robustness guarantees against data poisoning attacks and backdoor attacks. Moreover, our evaluation results on MNIST and CIFAR10 show that the intrinsic certified robustness guarantees of kNN and rNN outperform those provided by state-of-the-art certified defenses. Our results serve as standard baselines for future certified defenses against data poisoning attacks and backdoor attacks.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Jia","given":"Jinyuan"},{"family":"Liu","given":"Yupei"},{"family":"Cao","given":"Xiaoyu"},{"family":"Gong","given":"Neil Zhenqiang"}],"citation-key":"jiaCertifiedRobustnessNearest2021","DOI":"10.48550/arXiv.2012.03765","issued":{"date-parts":[["2021",12,2]]},"number":"arXiv:2012.03765","publisher":"arXiv","source":"arXiv.org","title":"Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks","type":"article","URL":"http://arxiv.org/abs/2012.03765"},
  {"id":"junaidkhanMuRelSGGMultimodalRelationship2025","abstract":"Neurosymbolic Scene Graph Generation (SGG) is a promising approach that jointly leverages the perception capabilities of deep neural networks and the reasoning capabilities of symbolic techniques for scene understanding and visual reasoning. SGG systematically captures semantic components, including objects and their relationships, in images, enabling structured representations of visual data. However, existing SGG methods exhibit constrained accuracy and limited expressiveness, particularly in longtail relationship prediction. To address these limitations, we present MuRelSGG, a novel neurosymbolic SGG framework that integrates a Transformer-based multimodal relationship prediction pipeline with common sense knowledge enrichment. This synergistic combination encapsulates global context, long-range dependencies, and complex object interactions to enhance relationship prediction in SGG. The proposed neurosymbolic architecture begins with object detection via Faster R-CNN, followed by a cascade of Multi-Head Attention Transformers (M-HAT) and Vision Transformers (ViT) for relationship prediction. Subsequently, CSKG enrichment refines and augments visual relationships, improving both accuracy and expressiveness. We conduct extensive evaluations on both the Visual Genome (VG) and GQA datasets to assess performance and generalizability. MuRelSGG achieves substantial gains in recall rates (VG: R@100 = 43.2, mR@100 = 14.9; GQA: R@100 = 42.1), outperforming state-of-the-art SGG techniques. Ablation studies confirm the critical contributions of M-HAT, ViT, linguistic features, CSKG enrichment and embedding similarity thresholds, demonstrating the effectiveness of structured knowledge integration for long-tail relationship prediction. These findings underscore the potential of combining deep learning architectures with structured knowledge bases to advance visual scene representation and reasoning.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Junaid Khan","given":"Muhammad"},{"family":"Masood Siddiqui","given":"Adil"},{"family":"Saeed Khan","given":"Hamid"},{"family":"Akram","given":"Faisal"},{"family":"Jaleed Khan","given":"M."}],"citation-key":"junaidkhanMuRelSGGMultimodalRelationship2025","container-title":"IEEE Access","container-title-short":"IEEE Access","DOI":"10.1109/ACCESS.2025.3551267","ISSN":"2169-3536","issued":{"date-parts":[["2025"]]},"language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","page":"47042-47054","source":"DOI.org (Crossref)","title":"MuRelSGG: Multimodal Relationship Prediction for Neurosymbolic Scene Graph Generation","title-short":"MuRelSGG","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/10925205/","volume":"13"},
  {"id":"ketkarIntroductionPyTorch2021","abstract":"The recent years have witnessed major releases of frameworks and tools to democratize deep learning to the masses. Today, we have a plethora of options at our disposal. A few popular names include PyTorch, TensorFlow, Keras, and MXNet—the list is never-ending. This chapter aims to provide an overview of PyTorch. We will be using PyTorch extensively throughout the book for implementing deep learning examples. Note that this chapter is not a comprehensive guide for PyTorch, so you should consult the additional materials suggested in the chapter for a deeper understanding of the framework. A basic overview will be offered and the necessary additions to the topic will be provided in the course of the examples implemented later in the book.","author":[{"family":"Ketkar","given":"Nikhil"},{"family":"Moolayil","given":"Jojo"}],"citation-key":"ketkarIntroductionPyTorch2021","container-title":"Deep Learning with Python: Learn Best Practices of Deep Learning Models with PyTorch","DOI":"10.1007/978-1-4842-5364-9_2","event-place":"Berkeley, CA","ISBN":"978-1-4842-5364-9","issued":{"date-parts":[["2021"]]},"page":"27–91","publisher":"Apress","publisher-place":"Berkeley, CA","title":"Introduction to PyTorch","type":"chapter","URL":"https://doi.org/10.1007/978-1-4842-5364-9_2"},
  {"id":"khanSurveyNeurosymbolicVisual2025","abstract":"Combining deep learning and common sense knowledge via neurosymbolic integration is essential for semantically rich scene representation and intuitive visual reasoning. This survey paper delves into data- and knowledge-driven scene representation and visual reasoning approaches based on deep learning, common sense knowledge and neurosymbolic integration. It explores how scene graph generation, a process that detects and analyses objects, visual relationships and attributes in scenes, serves as a symbolic scene representation. This representation forms the basis for higher-level visual reasoning tasks such as visual question answering, image captioning, image retrieval, image generation, and multimodal event processing. Infusing common sense knowledge, particularly through the use of heterogeneous knowledge graphs, improves the accuracy, expressiveness and reasoning ability of the representation and allows for intuitive downstream reasoning. Neurosymbolic integration in these approaches ranges from loose to tight coupling of neural and symbolic components. The paper reviews and categorises the state-of-the-art knowledge-based neurosymbolic approaches for scene representation based on the types of deep learning architecture, common sense knowledge source and neurosymbolic integration used. The paper also discusses the visual reasoning tasks, datasets, evaluation metrics, key challenges and future directions, providing a comprehensive review of this research area and motivating further research into knowledge-enhanced and data-driven neurosymbolic scene representation and visual reasoning.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Khan","given":"M Jaleed"},{"family":"Ilievski","given":"Filip"},{"family":"Breslin","given":"John G"},{"family":"Curry","given":"Edward"}],"citation-key":"khanSurveyNeurosymbolicVisual2025","container-title":"Neurosymbolic Artificial Intelligence","container-title-short":"Neurosymbolic Artificial Intelligence","DOI":"10.3233/NAI-240719","ISSN":"2949-8732, 2949-8732","issued":{"date-parts":[["2025",3]]},"language":"en","page":"NAI-240719","source":"DOI.org (Crossref)","title":"A survey of neurosymbolic visual reasoning with scene graphs and common sense knowledge","type":"article-journal","URL":"https://journals.sagepub.com/doi/10.3233/NAI-240719","volume":"1"},
  {"id":"kochSGRec3DSelfSupervised3D2023","abstract":"In the field of 3D scene understanding, 3D scene graphs have emerged as a new scene representation that combines geometric and semantic information about objects and their relationships. However, learning semantic 3D scene graphs in a fully supervised manner is inherently difficult as it requires not only object-level annotations but also relationship labels. While pre-training approaches have helped to boost the performance of many methods in various fields, pre-training for 3D scene graph prediction has received little attention. Furthermore, we find in this paper that classical contrastive point cloud-based pre-training approaches are ineffective for 3D scene graph learning. To this end, we present SGRec3D, a novel self-supervised pre-training method for 3D scene graph prediction. We propose to reconstruct the 3D input scene from a graph bottleneck as a pretext task. Pre-training SGRec3D does not require object relationship labels, making it possible to exploit large-scale 3D scene understanding datasets, which were off-limits for 3D scene graph learning before. Our experiments demonstrate that in contrast to recent point cloud-based pre-training approaches, our proposed pre-training improves the 3D scene graph prediction considerably, which results in SOTA performance, outperforming other 3D scene graph models by +10% on object prediction and +4% on relationship prediction. Additionally, we show that only using a small subset of 10% labeled data during fine-tuning is sufficient to outperform the same model without pre-training.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Koch","given":"Sebastian"},{"family":"Hermosilla","given":"Pedro"},{"family":"Vaskevicius","given":"Narunas"},{"family":"Colosi","given":"Mirco"},{"family":"Ropinski","given":"Timo"}],"citation-key":"kochSGRec3DSelfSupervised3D2023","DOI":"10.48550/arXiv.2309.15702","issued":{"date-parts":[["2023",11,6]]},"number":"arXiv:2309.15702","publisher":"arXiv","source":"arXiv.org","title":"SGRec3D: Self-Supervised 3D Scene Graph Learning via Object-Level Scene Reconstruction","title-short":"SGRec3D","type":"article","URL":"http://arxiv.org/abs/2309.15702"},
  {"id":"kramerScikitLearn2016","abstract":"scikit-learn is an open source machine learning library written in Python.","author":[{"family":"Kramer","given":"Oliver"}],"citation-key":"kramerScikitLearn2016","container-title":"Machine Learning for Evolution Strategies","DOI":"10.1007/978-3-319-33383-0_5","event-place":"Cham","ISBN":"978-3-319-33383-0","issued":{"date-parts":[["2016"]]},"page":"45–53","publisher":"Springer International Publishing","publisher-place":"Cham","title":"Scikit-Learn","type":"chapter","URL":"https://doi.org/10.1007/978-3-319-33383-0_5"},
  {"id":"LargescaleDatasetPruning","accessed":{"date-parts":[["2025",6,14]]},"citation-key":"LargescaleDatasetPruning","title":"Large-scale Dataset Pruning with Dynamic Uncertainty","type":"webpage","URL":"https://arxiv.org/html/2306.05175v3"},
  {"id":"lecunDeepLearning2015","abstract":"Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.","author":[{"family":"LeCun","given":"Yann"},{"family":"Bengio","given":"Yoshua"},{"family":"Hinton","given":"Geoffrey"}],"citation-key":"lecunDeepLearning2015","container-title":"Nature","container-title-short":"Nature","DOI":"10.1038/nature14539","ISSN":"1476-4687","issue":"7553","issued":{"date-parts":[["2015",5,1]]},"page":"436-444","title":"Deep learning","type":"article-journal","URL":"https://doi.org/10.1038/nature14539","volume":"521"},
  {"id":"leiComprehensiveSurveyDataset2024","abstract":"Deep learning technology has developed unprecedentedly in the last decade and has become the primary choice in many application domains. This progress is mainly attributed to a systematic collaboration in which rapidly growing computing resources encourage advanced algorithms to deal with massive data. However, it has gradually become challenging to handle the unlimited growth of data with limited computing power. To this end, diverse approaches are proposed to improve data processing efficiency. Dataset distillation, a dataset reduction method, addresses this problem by synthesizing a small typical dataset from substantial data and has attracted much attention from the deep learning community. Existing dataset distillation methods can be taxonomized into meta-learning and data matching frameworks according to whether they explicitly mimic the performance of target data. Although dataset distillation has shown surprising performance in compressing datasets, there are still several limitations such as distilling high-resolution data or data with complex label spaces. This paper provides a holistic understanding of dataset distillation from multiple aspects, including distillation frameworks and algorithms, factorized dataset distillation, performance comparison, and applications. Finally, we discuss challenges and promising directions to further promote future studies on dataset distillation.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Lei","given":"Shiye"},{"family":"Tao","given":"Dacheng"}],"citation-key":"leiComprehensiveSurveyDataset2024","container-title":"IEEE Transactions on Pattern Analysis and Machine Intelligence","container-title-short":"IEEE Trans. Pattern Anal. Mach. Intell.","DOI":"10.1109/TPAMI.2023.3322540","ISSN":"0162-8828, 2160-9292, 1939-3539","issue":"1","issued":{"date-parts":[["2024",1]]},"page":"17-32","source":"arXiv.org","title":"A Comprehensive Survey of Dataset Distillation","type":"article-journal","URL":"http://arxiv.org/abs/2301.05603","volume":"46"},
  {"id":"liGenerativeDatasetDistillation2024","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Li","given":"Longzhen"},{"family":"Li","given":"Guang"},{"family":"Togo","given":"Ren"},{"family":"Maeda","given":"Keisuke"},{"family":"Ogawa","given":"Takahiro"},{"family":"Haseyama","given":"Miki"}],"citation-key":"liGenerativeDatasetDistillation2024","event-title":"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition","issued":{"date-parts":[["2024"]]},"language":"en","page":"7664-7671","source":"openaccess.thecvf.com","title":"Generative Dataset Distillation: Balancing Global Structure and Local Details","title-short":"Generative Dataset Distillation","type":"paper-conference","URL":"https://openaccess.thecvf.com/content/CVPR2024W/DDCV/html/Li_Generative_Dataset_Distillation_Balancing_Global_Structure_and_Local_Details_CVPRW_2024_paper.html"},
  {"id":"lorelloKANDYBenchmarkIncremental2024","abstract":"Artificial intelligence is continuously seeking novel challenges and benchmarks to effectively measure performance and to advance the state-of-the-art. In this paper we introduce KANDY, a benchmarking framework that can be used to generate a variety of learning and reasoning tasks inspired by Kandinsky patterns. By creating curricula of binary classification tasks with increasing complexity and with sparse supervisions, KANDY can be used to implement benchmarks for continual and semi-supervised learning, with a specific focus on symbol compositionality. Classification rules are also provided in the ground truth to enable analysis of interpretable solutions. Together with the benchmark generation pipeline, we release two curricula, an easier and a harder one, that we propose as new challenges for the research community. With a thorough experimental evaluation, we show how both state-of-the-art neural models and purely symbolic approaches struggle with solving most of the tasks, thus calling for the application of advanced neuro-symbolic methods trained over time.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Lorello","given":"Luca Salvatore"},{"family":"Lippi","given":"Marco"},{"family":"Melacci","given":"Stefano"}],"citation-key":"lorelloKANDYBenchmarkIncremental2024","DOI":"10.48550/arXiv.2402.17431","issued":{"date-parts":[["2024",2,27]]},"number":"arXiv:2402.17431","publisher":"arXiv","source":"arXiv.org","title":"The KANDY Benchmark: Incremental Neuro-Symbolic Learning and Reasoning with Kandinsky Patterns","title-short":"The KANDY Benchmark","type":"article","URL":"http://arxiv.org/abs/2402.17431"},
  {"id":"Matplotlib393Documentation","accessed":{"date-parts":[["2025",2,24]]},"citation-key":"Matplotlib393Documentation","title":"Matplotlib 3.9.3 documentation","type":"webpage","URL":"https://matplotlib.org/3.9.3/index.html"},
  {"id":"mendezCUBICConceptEmbeddings2025","abstract":"Deep vision models often rely on biases learned from spurious correlations in datasets. To identify these biases, methods that interpret high-level, human-understandable concepts are more effective than those relying primarily on low-level features like heatmaps. A major challenge for these concept-based methods is the lack of image annotations indicating potentially bias-inducing concepts, since creating such annotations requires detailed labeling for each dataset and concept, which is highly labor-intensive. We present CUBIC (Concept embeddings for Unsupervised Bias IdentifiCation), a novel method that automatically discovers interpretable concepts that may bias classifier behavior. Unlike existing approaches, CUBIC does not rely on predefined bias candidates or examples of model failures tied to specific biases, as such information is not always available. Instead, it leverages image-text latent space and linear classifier probes to examine how the latent representation of a superclass label$\\unicode{x2014}$shared by all instances in the dataset$\\unicode{x2014}$is influenced by the presence of a given concept. By measuring these shifts against the normal vector to the classifier's decision boundary, CUBIC identifies concepts that significantly influence model predictions. Our experiments demonstrate that CUBIC effectively uncovers previously unknown biases using Vision-Language Models (VLMs) without requiring the samples in the dataset where the classifier underperforms or prior knowledge of potential biases.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Méndez","given":"David"},{"family":"Bontempo","given":"Gianpaolo"},{"family":"Ficarra","given":"Elisa"},{"family":"Confalonieri","given":"Roberto"},{"family":"Díaz-Rodríguez","given":"Natalia"}],"citation-key":"mendezCUBICConceptEmbeddings2025","DOI":"10.48550/arXiv.2505.11060","issued":{"date-parts":[["2025",5,16]]},"number":"arXiv:2505.11060","publisher":"arXiv","source":"arXiv.org","title":"CUBIC: Concept Embeddings for Unsupervised Bias Identification using VLMs","title-short":"CUBIC","type":"article","URL":"http://arxiv.org/abs/2505.11060"},
  {"id":"MNISTDataset","abstract":"The MNIST database of handwritten digits (http://yann.lecun.com)","accessed":{"date-parts":[["2025",2,24]]},"citation-key":"MNISTDataset","language":"en","title":"MNIST Dataset","type":"webpage","URL":"https://www.kaggle.com/datasets/hojjatk/mnist-dataset"},
  {"id":"molinaMASWChainsMemeticAlgorithm2010","abstract":"Memetic algorithms are effective algorithms to obtain reliable and accurate solutions for complex continuous optimization problems. Nowadays, high dimensional optimization problems are an interesting field of research. The high dimensionality introduces new problems for the optimization process, requiring more scalable algorithms that, at the same time, could explore better the higher domain space around each solution. In this work, we proposed a memetic algorithm, MA-SW-Chains, for large scale global optimization. This algorithm assigns to each individual a local search intensity that depends on its features, by chaining different local search applications. MA-SW-Chains is an adaptation to large scale optimization of a previous algorithm, MA-CMA-Chains, to improve its performance on high-dimensional problems. Finally, we present the results obtained by our proposal using the benchmark problems defined in the Special Session of Large Scale Global Optimization on the IEEE Congress on Evolutionary Computation in 2010.","accessed":{"date-parts":[["2025",6,12]]},"author":[{"family":"Molina","given":"Daniel"},{"family":"Lozano","given":"Manuel"},{"family":"Herrera","given":"Francisco"}],"citation-key":"molinaMASWChainsMemeticAlgorithm2010","container-title":"IEEE Congress on Evolutionary Computation","DOI":"10.1109/CEC.2010.5586034","event-title":"IEEE Congress on Evolutionary Computation","ISSN":"1941-0026","issued":{"date-parts":[["2010",7]]},"page":"1-8","source":"IEEE Xplore","title":"MA-SW-Chains: Memetic algorithm based on local search chains for large scale continuous global optimization","title-short":"MA-SW-Chains","type":"paper-conference","URL":"https://ieeexplore.ieee.org/abstract/document/5586034"},
  {"id":"moscatoEvolutionSearchOptimization2000","author":[{"family":"Moscato","given":"Pablo"}],"citation-key":"moscatoEvolutionSearchOptimization2000","container-title":"Caltech Concurrent Computation Program","issued":{"date-parts":[["2000",10]]},"title":"On Evolution, Search, Optimization, Genetic Algorithms and Martial Arts - Towards Memetic Algorithms","type":"article-journal"},
  {"id":"neriHandbookMemeticAlgorithms2012","citation-key":"neriHandbookMemeticAlgorithms2012","collection-editor":[{"family":"Kacprzyk","given":"Janusz"}],"collection-title":"Studies in Computational Intelligence","DOI":"10.1007/978-3-642-23247-3","editor":[{"family":"Neri","given":"Ferrante"},{"family":"Cotta","given":"Carlos"},{"family":"Moscato","given":"Pablo"}],"event-place":"Berlin, Heidelberg","ISBN":"978-3-642-23246-6 978-3-642-23247-3","issued":{"date-parts":[["2012"]]},"language":"en","license":"http://www.springer.com/tdm","publisher":"Springer","publisher-place":"Berlin, Heidelberg","source":"DOI.org (Crossref)","title":"Handbook of Memetic Algorithms","type":"book","URL":"http://link.springer.com/10.1007/978-3-642-23247-3","volume":"379"},
  {"id":"NotionGestionTareas","abstract":"Crea un panel personalizado para gestionar todas tus tareas de trabajo personales, a la vez que aportas información relevante de todo tu espacio de trabajo de Notion.","accessed":{"date-parts":[["2025",2,27]]},"citation-key":"NotionGestionTareas","container-title":"Notion","language":"es-es","title":"Notion - Gestión de Tareas","type":"webpage","URL":"https://www.notion.com/es-es/help/guides/personal-work-dashboard"},
  {"id":"NumPyV20Manual","accessed":{"date-parts":[["2025",2,24]]},"citation-key":"NumPyV20Manual","title":"NumPy v2.0 Manual","type":"webpage","URL":"https://numpy.org/doc/2.0/index.html"},
  {"id":"Openpyxl313Documentation","accessed":{"date-parts":[["2025",5,3]]},"citation-key":"Openpyxl313Documentation","title":"Openpyxl 3.1.3 documentation","type":"webpage","URL":"https://openpyxl.readthedocs.io/en/stable/"},
  {"id":"OriginalArtImages","abstract":"Dataset with about 9000 images containing 5 types of arts","accessed":{"date-parts":[["2025",2,24]]},"citation-key":"OriginalArtImages","language":"en","title":"(Original) Art Images: Drawing/Painting/Sculptures/Engravings","title-short":"Art Images","type":"webpage","URL":"https://www.kaggle.com/datasets/thedownhill/art-images-drawings-painting-sculpture-engraving"},
  {"id":"OverviewGoogleCloud","abstract":"An overview of Google Cloud Platform.","accessed":{"date-parts":[["2025",2,25]]},"citation-key":"OverviewGoogleCloud","language":"es-419-x-mtfrom-en","title":"Overview Google Cloud","type":"webpage","URL":"https://cloud.google.com/docs/overview?hl=es-419"},
  {"id":"Pandas223Documentation","accessed":{"date-parts":[["2025",6,8]]},"citation-key":"Pandas223Documentation","title":"Pandas 2.2.3 documentation","type":"webpage","URL":"https://pandas.pydata.org/pandas-docs/version/2.2/index.html"},
  {"id":"pattersonCarbonEmissionsLarge2021","abstract":"The computation demand for machine learning (ML) has grown rapidly recently, which comes with a number of costs. Estimating the energy cost helps measure its environmental impact and finding greener strategies, yet it is challenging without detailed information. We calculate the energy use and carbon footprint of several recent large models-T5, Meena, GShard, Switch Transformer, and GPT-3-and refine earlier estimates for the neural architecture search that found Evolved Transformer. We highlight the following opportunities to improve energy efficiency and CO2 equivalent emissions (CO2e): Large but sparsely activated DNNs can consume <1/10th the energy of large, dense DNNs without sacrificing accuracy despite using as many or even more parameters. Geographic location matters for ML workload scheduling since the fraction of carbon-free energy and resulting CO2e vary ~5X-10X, even within the same country and the same organization. We are now optimizing where and when large models are trained. Specific datacenter infrastructure matters, as Cloud datacenters can be ~1.4-2X more energy efficient than typical datacenters, and the ML-oriented accelerators inside them can be ~2-5X more effective than off-the-shelf systems. Remarkably, the choice of DNN, datacenter, and processor can reduce the carbon footprint up to ~100-1000X. These large factors also make retroactive estimates of energy cost difficult. To avoid miscalculations, we believe ML papers requiring large computational resources should make energy consumption and CO2e explicit when practical. We are working to be more transparent about energy use and CO2e in our future research. To help reduce the carbon footprint of ML, we believe energy usage and CO2e should be a key metric in evaluating models, and we are collaborating with MLPerf developers to include energy usage during training and inference in this industry standard benchmark.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Patterson","given":"David"},{"family":"Gonzalez","given":"Joseph"},{"family":"Le","given":"Quoc"},{"family":"Liang","given":"Chen"},{"family":"Munguia","given":"Lluis-Miquel"},{"family":"Rothchild","given":"Daniel"},{"family":"So","given":"David"},{"family":"Texier","given":"Maud"},{"family":"Dean","given":"Jeff"}],"citation-key":"pattersonCarbonEmissionsLarge2021","DOI":"10.48550/arXiv.2104.10350","issued":{"date-parts":[["2021",4,23]]},"number":"arXiv:2104.10350","publisher":"arXiv","source":"arXiv.org","title":"Carbon Emissions and Large Neural Network Training","type":"article","URL":"http://arxiv.org/abs/2104.10350"},
  {"id":"pmlr-v81-buolamwini18a","abstract":"Recent studies demonstrate that machine learning algorithms can discriminate based on classes like race and gender. In this work, we present an approach to evaluate bias present in automated facial analysis algorithms and datasets with respect to phenotypic subgroups. Using the dermatologist approved Fitzpatrick Skin Type classification system, we characterize the gender and skin type distribution of two facial analysis benchmarks, IJB-A and Adience. We find that these datasets are overwhelmingly composed of lighter-skinned subjects (79.6","author":[{"family":"Buolamwini","given":"Joy"},{"family":"Gebru","given":"Timnit"}],"citation-key":"pmlr-v81-buolamwini18a","collection-title":"Proceedings of Machine Learning Research","container-title":"Proceedings of the 1st Conference on Fairness, Accountability and Transparency","editor":[{"family":"Friedler","given":"Sorelle A."},{"family":"Wilson","given":"Christo"}],"issued":{"date-parts":[["2018",2,23],["2018",2,24]]},"page":"77–91","publisher":"PMLR","title":"Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification","type":"paper-conference","URL":"https://proceedings.mlr.press/v81/buolamwini18a.html","volume":"81"},
  {"id":"PolarsPythonAPI","accessed":{"date-parts":[["2025",2,24]]},"citation-key":"PolarsPythonAPI","title":"Polars — Python API reference","type":"webpage","URL":"https://docs.pola.rs/api/python/stable/reference/"},
  {"id":"qmeeusEarlyStoppingDisscussion2018","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"qmeeus","given":""}],"citation-key":"qmeeusEarlyStoppingDisscussion2018","container-title":"Data Science Stack Exchange","genre":"Forum post","issued":{"date-parts":[["2018",8,21]]},"title":"Early Stopping Disscussion","type":"post","URL":"https://datascience.stackexchange.com/q/37186"},
  {"id":"realRegularizedEvolutionImage2019","abstract":"The effort devoted to hand-crafting neural network image classifiers has motivated the use of architecture search to discover them automatically. Although evolutionary algorithms have been repeatedly applied to neural network topologies, the image classifiers thus discovered have remained inferior to human-crafted ones. Here, we evolve an image classifier---AmoebaNet-A---that surpasses hand-designs for the first time. To do this, we modify the tournament selection evolutionary algorithm by introducing an age property to favor the younger genotypes. Matching size, AmoebaNet-A has comparable accuracy to current state-of-the-art ImageNet models discovered with more complex architecture-search methods. Scaled to larger size, AmoebaNet-A sets a new state-of-the-art 83.9% / 96.6% top-5 ImageNet accuracy. In a controlled comparison against a well known reinforcement learning algorithm, we give evidence that evolution can obtain results faster with the same hardware, especially at the earlier stages of the search. This is relevant when fewer compute resources are available. Evolution is, thus, a simple method to effectively discover high-quality architectures.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Real","given":"Esteban"},{"family":"Aggarwal","given":"Alok"},{"family":"Huang","given":"Yanping"},{"family":"Le","given":"Quoc V."}],"citation-key":"realRegularizedEvolutionImage2019","DOI":"10.48550/arXiv.1802.01548","issued":{"date-parts":[["2019",2,16]]},"number":"arXiv:1802.01548","publisher":"arXiv","source":"arXiv.org","title":"Regularized Evolution for Image Classifier Architecture Search","type":"article","URL":"http://arxiv.org/abs/1802.01548"},
  {"id":"ReglamentoIA2024","author":[{"literal":"Parlamento Europeo y Consejo de la Unión Europea"}],"citation-key":"ReglamentoIA2024","issued":{"date-parts":[["2024",7]]},"language":"spanish","title":"Reglamento (UE) 2024/1689 del Parlamento Europeo y del Consejo, de 13 de junio de 2024, sobre normas armonizadas en materia de inteligencia artificial","type":"document","URL":"https://eur-lex.europa.eu/legal-content/ES/TXT/?uri=CELEX:32024R1689"},
  {"id":"RegulationEU20242024","accessed":{"date-parts":[["2025",6,14]]},"authority":"CONSIL, EP","citation-key":"RegulationEU20242024","issued":{"date-parts":[["2024",6,13]]},"language":"en","title":"Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and Directives 2014/90/EU, (EU) 2016/797 and (EU) 2020/1828 (Artificial Intelligence Act) (Text with EEA relevance)","type":"legislation","URL":"http://data.europa.eu/eli/reg/2024/1689/oj/eng"},
  {"id":"ResNet50","abstract":"Model Description","accessed":{"date-parts":[["2025",2,24]]},"citation-key":"ResNet50","container-title":"PyTorch","language":"en","title":"ResNet50","type":"webpage","URL":"https://pytorch.org/hub/nvidia_deeplearningexamples_resnet50/"},
  {"id":"reuelBetterBenchAssessingAI2024","abstract":"AI models are increasingly prevalent in high-stakes environments, necessitating thorough assessment of their capabilities and risks. Benchmarks are popular for measuring these attributes and for comparing model performance, tracking progress, and identifying weaknesses in foundation and non-foundation models. They can inform model selection for downstream tasks and influence policy initiatives. However, not all benchmarks are the same: their quality depends on their design and usability. In this paper, we develop an assessment framework considering 46 best practices across an AI benchmark's lifecycle and evaluate 24 AI benchmarks against it. We find that there exist large quality differences and that commonly used benchmarks suffer from significant issues. We further find that most benchmarks do not report statistical significance of their results nor allow for their results to be easily replicated. To support benchmark developers in aligning with best practices, we provide a checklist for minimum quality assurance based on our assessment. We also develop a living repository of benchmark assessments to support benchmark comparability, accessible at betterbench.stanford.edu.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Reuel","given":"Anka"},{"family":"Hardy","given":"Amelia"},{"family":"Smith","given":"Chandler"},{"family":"Lamparth","given":"Max"},{"family":"Hardy","given":"Malcolm"},{"family":"Kochenderfer","given":"Mykel J."}],"citation-key":"reuelBetterBenchAssessingAI2024","DOI":"10.48550/arXiv.2411.12990","issued":{"date-parts":[["2024",11,20]]},"number":"arXiv:2411.12990","publisher":"arXiv","source":"arXiv.org","title":"BetterBench: Assessing AI Benchmarks, Uncovering Issues, and Establishing Best Practices","title-short":"BetterBench","type":"article","URL":"http://arxiv.org/abs/2411.12990"},
  {"id":"RockPaperScissors","abstract":"Download 2925 free images labeled for classification.","accessed":{"date-parts":[["2025",2,24]]},"citation-key":"RockPaperScissors","container-title":"Roboflow","title":"Rock Paper Scissors Dataset","type":"webpage","URL":"https://public.roboflow.com/classification/rock-paper-scissors"},
  {"id":"rolnickDeepLearningRobust2018","abstract":"Deep neural networks trained on large supervised datasets have led to impressive results in image classification and other tasks. However, well-annotated datasets can be time-consuming and expensive to collect, lending increased interest to larger but noisy datasets that are more easily obtained. In this paper, we show that deep neural networks are capable of generalizing from training data for which true labels are massively outnumbered by incorrect labels. We demonstrate remarkably high test performance after training on corrupted data from MNIST, CIFAR, and ImageNet. For example, on MNIST we obtain test accuracy above 90 percent even after each clean training example has been diluted with 100 randomly-labeled examples. Such behavior holds across multiple patterns of label noise, even when erroneous labels are biased towards confusing classes. We show that training in this regime requires a significant but manageable increase in dataset size that is related to the factor by which correct labels have been diluted. Finally, we provide an analysis of our results that shows how increasing noise decreases the effective batch size.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Rolnick","given":"David"},{"family":"Veit","given":"Andreas"},{"family":"Belongie","given":"Serge"},{"family":"Shavit","given":"Nir"}],"citation-key":"rolnickDeepLearningRobust2018","DOI":"10.48550/arXiv.1705.10694","issued":{"date-parts":[["2018",2,26]]},"number":"arXiv:1705.10694","publisher":"arXiv","source":"arXiv.org","title":"Deep Learning is Robust to Massive Label Noise","type":"article","URL":"http://arxiv.org/abs/1705.10694"},
  {"id":"SalarioParaData","abstract":"Data Scientist en España perciben un salario medio mensual € 3.389. Prueba la herramienta de salarios de Talent.com y descubre cuál es el salario medio de los profesionales de la industria.","accessed":{"date-parts":[["2025",2,24]]},"citation-key":"SalarioParaData","container-title":"Talent.com","language":"es-es","title":"Salario para Data Scientist en España - Salario Medio","type":"webpage","URL":"https://es.talent.com/salary"},
  {"id":"salman2023data","author":[{"family":"Salman","given":"Hisham"},{"family":"Zhan","given":"Xingchao"},{"family":"Krishnan","given":"Ranjit"},{"family":"Qi","given":"Yingyu"},{"family":"Li","given":"Yingya"},{"family":"Wang","given":"Xing"},{"family":"Wang","given":"Zhangyang"}],"citation-key":"salman2023data","container-title":"arXiv preprint arXiv:2306.05175","issued":{"date-parts":[["2023"]]},"title":"Data selection for efficient model training: an overview","type":"article-journal"},
  {"id":"sandlerMobileNetV2InvertedResiduals2019","abstract":"In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. The MobileNetV2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input an MobileNetV2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on Imagenet classification, COCO object detection, VOC image segmentation. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as the number of parameters","author":[{"family":"Sandler","given":"Mark"},{"family":"Howard","given":"Andrew"},{"family":"Zhu","given":"Menglong"},{"family":"Zhmoginov","given":"Andrey"},{"family":"Chen","given":"Liang-Chieh"}],"citation-key":"sandlerMobileNetV2InvertedResiduals2019","DOI":"10.48550/arXiv.1801.04381","issued":{"date-parts":[["2019",3,21]]},"number":"arXiv:1801.04381","publisher":"arXiv","source":"arXiv.org","title":"MobileNetV2: Inverted Residuals and Linear Bottlenecks","title-short":"MobileNetV2","type":"article","URL":"http://arxiv.org/abs/1801.04381"},
  {"id":"ScrumGuide","accessed":{"date-parts":[["2025",2,25]]},"citation-key":"ScrumGuide","title":"Scrum Guide","type":"webpage","URL":"https://scrumguides.org/scrum-guide.html"},
  {"id":"Seaborn0132Documentation","accessed":{"date-parts":[["2025",5,3]]},"citation-key":"Seaborn0132Documentation","title":"Seaborn 0.13.2 documentation","type":"webpage","URL":"https://seaborn.pydata.org/tutorial.html"},
  {"id":"shangIncrementalResidualConcept2024","abstract":"Concept Bottleneck Models (CBMs) map the black-box visual representations extracted by deep neural networks onto a set of interpretable concepts and use the concepts to make predictions, enhancing the transparency of the decision-making process. Multimodal pre-trained models can match visual representations with textual concept embeddings, allowing for obtaining the interpretable concept bottleneck without the expertise concept annotations. Recent research has focused on the concept bank establishment and the high-quality concept selection. However, it is challenging to construct a comprehensive concept bank through humans or large language models, which severely limits the performance of CBMs. In this work, we propose the Incremental Residual Concept Bottleneck Model (Res-CBM) to address the challenge of concept completeness. Specifically, the residual concept bottleneck model employs a set of optimizable vectors to complete missing concepts, then the incremental concept discovery module converts the complemented vectors with unclear meanings into potential concepts in the candidate concept bank. Our approach can be applied to any user-defined concept bank, as a post-hoc processing method to enhance the performance of any CBMs. Furthermore, to measure the descriptive efficiency of CBMs, the Concept Utilization Efficiency (CUE) metric is proposed. Experiments show that the Res-CBM outperforms the current state-of-the-art methods in terms of both accuracy and efficiency and achieves comparable performance to black-box models across multiple datasets.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Shang","given":"Chenming"},{"family":"Zhou","given":"Shiji"},{"family":"Zhang","given":"Hengyuan"},{"family":"Ni","given":"Xinzhe"},{"family":"Yang","given":"Yujiu"},{"family":"Wang","given":"Yuwang"}],"citation-key":"shangIncrementalResidualConcept2024","DOI":"10.48550/arXiv.2404.08978","issued":{"date-parts":[["2024",4,17]]},"number":"arXiv:2404.08978","publisher":"arXiv","source":"arXiv.org","title":"Incremental Residual Concept Bottleneck Models","type":"article","URL":"http://arxiv.org/abs/2404.08978"},
  {"id":"shortenSurveyImageData2019","abstract":"Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.","author":[{"family":"Shorten","given":"Connor"},{"family":"Khoshgoftaar","given":"Taghi M."}],"citation-key":"shortenSurveyImageData2019","container-title":"Journal of Big Data","container-title-short":"Journal of Big Data","DOI":"10.1186/s40537-019-0197-0","ISSN":"2196-1115","issue":"1","issued":{"date-parts":[["2019",7,6]]},"page":"60","title":"A survey on Image Data Augmentation for Deep Learning","type":"article-journal","URL":"https://doi.org/10.1186/s40537-019-0197-0","volume":"6"},
  {"id":"sinhaTeSTTesttimeSelfTraining2022","abstract":"Despite their recent success, deep neural networks continue to perform poorly when they encounter distribution shifts at test time. Many recently proposed approaches try to counter this by aligning the model to the new distribution prior to inference. With no labels available this requires unsupervised objectives to adapt the model on the observed test data. In this paper, we propose Test-Time Self-Training (TeST): a technique that takes as input a model trained on some source data and a novel data distribution at test time, and learns invariant and robust representations using a student-teacher framework. We find that models adapted using TeST significantly improve over baseline test-time adaptation algorithms. TeST achieves competitive performance to modern domain adaptation algorithms, while having access to 5-10x less data at time of adaption. We thoroughly evaluate a variety of baselines on two tasks: object detection and image segmentation and find that models adapted with TeST. We find that TeST sets the new state-of-the art for test-time domain adaptation algorithms.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Sinha","given":"Samarth"},{"family":"Gehler","given":"Peter"},{"family":"Locatello","given":"Francesco"},{"family":"Schiele","given":"Bernt"}],"citation-key":"sinhaTeSTTesttimeSelfTraining2022","DOI":"10.48550/arXiv.2209.11459","issued":{"date-parts":[["2022",9,23]]},"number":"arXiv:2209.11459","publisher":"arXiv","source":"arXiv.org","title":"TeST: Test-time Self-Training under Distribution Shift","title-short":"TeST","type":"article","URL":"http://arxiv.org/abs/2209.11459"},
  {"id":"sorscherNeuralScalingLaws2023","abstract":"Widely observed neural scaling laws, in which error falls off as a power of the training set size, model size, or both, have driven substantial performance improvements in deep learning. However, these improvements through scaling alone require considerable costs in compute and energy. Here we focus on the scaling of error with dataset size and show how in theory we can break beyond power law scaling and potentially even reduce it to exponential scaling instead if we have access to a high-quality data pruning metric that ranks the order in which training examples should be discarded to achieve any pruned dataset size. We then test this improved scaling prediction with pruned dataset size empirically, and indeed observe better than power law scaling in practice on ResNets trained on CIFAR-10, SVHN, and ImageNet. Next, given the importance of finding high-quality pruning metrics, we perform the first large-scale benchmarking study of ten different data pruning metrics on ImageNet. We find most existing high performing metrics scale poorly to ImageNet, while the best are computationally intensive and require labels for every image. We therefore developed a new simple, cheap and scalable self-supervised pruning metric that demonstrates comparable performance to the best supervised metrics. Overall, our work suggests that the discovery of good data-pruning metrics may provide a viable path forward to substantially improved neural scaling laws, thereby reducing the resource costs of modern deep learning.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Sorscher","given":"Ben"},{"family":"Geirhos","given":"Robert"},{"family":"Shekhar","given":"Shashank"},{"family":"Ganguli","given":"Surya"},{"family":"Morcos","given":"Ari S."}],"citation-key":"sorscherNeuralScalingLaws2023","DOI":"10.48550/arXiv.2206.14486","issued":{"date-parts":[["2023",4,21]]},"number":"arXiv:2206.14486","publisher":"arXiv","source":"arXiv.org","title":"Beyond neural scaling laws: beating power law scaling via data pruning","title-short":"Beyond neural scaling laws","type":"article","URL":"http://arxiv.org/abs/2206.14486"},
  {"id":"srivastavaImitationGameQuantifying2023","abstract":"Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit \"breakthrough\" behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Srivastava","given":"Aarohi"},{"family":"Rastogi","given":"Abhinav"},{"family":"Rao","given":"Abhishek"},{"family":"Shoeb","given":"Abu Awal Md"},{"family":"Abid","given":"Abubakar"},{"family":"Fisch","given":"Adam"},{"family":"Brown","given":"Adam R."},{"family":"Santoro","given":"Adam"},{"family":"Gupta","given":"Aditya"},{"family":"Garriga-Alonso","given":"Adrià"},{"family":"Kluska","given":"Agnieszka"},{"family":"Lewkowycz","given":"Aitor"},{"family":"Agarwal","given":"Akshat"},{"family":"Power","given":"Alethea"},{"family":"Ray","given":"Alex"},{"family":"Warstadt","given":"Alex"},{"family":"Kocurek","given":"Alexander W."},{"family":"Safaya","given":"Ali"},{"family":"Tazarv","given":"Ali"},{"family":"Xiang","given":"Alice"},{"family":"Parrish","given":"Alicia"},{"family":"Nie","given":"Allen"},{"family":"Hussain","given":"Aman"},{"family":"Askell","given":"Amanda"},{"family":"Dsouza","given":"Amanda"},{"family":"Slone","given":"Ambrose"},{"family":"Rahane","given":"Ameet"},{"family":"Iyer","given":"Anantharaman S."},{"family":"Andreassen","given":"Anders"},{"family":"Madotto","given":"Andrea"},{"family":"Santilli","given":"Andrea"},{"family":"Stuhlmüller","given":"Andreas"},{"family":"Dai","given":"Andrew"},{"family":"La","given":"Andrew"},{"family":"Lampinen","given":"Andrew"},{"family":"Zou","given":"Andy"},{"family":"Jiang","given":"Angela"},{"family":"Chen","given":"Angelica"},{"family":"Vuong","given":"Anh"},{"family":"Gupta","given":"Animesh"},{"family":"Gottardi","given":"Anna"},{"family":"Norelli","given":"Antonio"},{"family":"Venkatesh","given":"Anu"},{"family":"Gholamidavoodi","given":"Arash"},{"family":"Tabassum","given":"Arfa"},{"family":"Menezes","given":"Arul"},{"family":"Kirubarajan","given":"Arun"},{"family":"Mullokandov","given":"Asher"},{"family":"Sabharwal","given":"Ashish"},{"family":"Herrick","given":"Austin"},{"family":"Efrat","given":"Avia"},{"family":"Erdem","given":"Aykut"},{"family":"Karakaş","given":"Ayla"},{"family":"Roberts","given":"B. Ryan"},{"family":"Loe","given":"Bao Sheng"},{"family":"Zoph","given":"Barret"},{"family":"Bojanowski","given":"Bartłomiej"},{"family":"Özyurt","given":"Batuhan"},{"family":"Hedayatnia","given":"Behnam"},{"family":"Neyshabur","given":"Behnam"},{"family":"Inden","given":"Benjamin"},{"family":"Stein","given":"Benno"},{"family":"Ekmekci","given":"Berk"},{"family":"Lin","given":"Bill Yuchen"},{"family":"Howald","given":"Blake"},{"family":"Orinion","given":"Bryan"},{"family":"Diao","given":"Cameron"},{"family":"Dour","given":"Cameron"},{"family":"Stinson","given":"Catherine"},{"family":"Argueta","given":"Cedrick"},{"family":"Ramírez","given":"César Ferri"},{"family":"Singh","given":"Chandan"},{"family":"Rathkopf","given":"Charles"},{"family":"Meng","given":"Chenlin"},{"family":"Baral","given":"Chitta"},{"family":"Wu","given":"Chiyu"},{"family":"Callison-Burch","given":"Chris"},{"family":"Waites","given":"Chris"},{"family":"Voigt","given":"Christian"},{"family":"Manning","given":"Christopher D."},{"family":"Potts","given":"Christopher"},{"family":"Ramirez","given":"Cindy"},{"family":"Rivera","given":"Clara E."},{"family":"Siro","given":"Clemencia"},{"family":"Raffel","given":"Colin"},{"family":"Ashcraft","given":"Courtney"},{"family":"Garbacea","given":"Cristina"},{"family":"Sileo","given":"Damien"},{"family":"Garrette","given":"Dan"},{"family":"Hendrycks","given":"Dan"},{"family":"Kilman","given":"Dan"},{"family":"Roth","given":"Dan"},{"family":"Freeman","given":"Daniel"},{"family":"Khashabi","given":"Daniel"},{"family":"Levy","given":"Daniel"},{"family":"González","given":"Daniel Moseguí"},{"family":"Perszyk","given":"Danielle"},{"family":"Hernandez","given":"Danny"},{"family":"Chen","given":"Danqi"},{"family":"Ippolito","given":"Daphne"},{"family":"Gilboa","given":"Dar"},{"family":"Dohan","given":"David"},{"family":"Drakard","given":"David"},{"family":"Jurgens","given":"David"},{"family":"Datta","given":"Debajyoti"},{"family":"Ganguli","given":"Deep"},{"family":"Emelin","given":"Denis"},{"family":"Kleyko","given":"Denis"},{"family":"Yuret","given":"Deniz"},{"family":"Chen","given":"Derek"},{"family":"Tam","given":"Derek"},{"family":"Hupkes","given":"Dieuwke"},{"family":"Misra","given":"Diganta"},{"family":"Buzan","given":"Dilyar"},{"family":"Mollo","given":"Dimitri Coelho"},{"family":"Yang","given":"Diyi"},{"family":"Lee","given":"Dong-Ho"},{"family":"Schrader","given":"Dylan"},{"family":"Shutova","given":"Ekaterina"},{"family":"Cubuk","given":"Ekin Dogus"},{"family":"Segal","given":"Elad"},{"family":"Hagerman","given":"Eleanor"},{"family":"Barnes","given":"Elizabeth"},{"family":"Donoway","given":"Elizabeth"},{"family":"Pavlick","given":"Ellie"},{"family":"Rodola","given":"Emanuele"},{"family":"Lam","given":"Emma"},{"family":"Chu","given":"Eric"},{"family":"Tang","given":"Eric"},{"family":"Erdem","given":"Erkut"},{"family":"Chang","given":"Ernie"},{"family":"Chi","given":"Ethan A."},{"family":"Dyer","given":"Ethan"},{"family":"Jerzak","given":"Ethan"},{"family":"Kim","given":"Ethan"},{"family":"Manyasi","given":"Eunice Engefu"},{"family":"Zheltonozhskii","given":"Evgenii"},{"family":"Xia","given":"Fanyue"},{"family":"Siar","given":"Fatemeh"},{"family":"Martínez-Plumed","given":"Fernando"},{"family":"Happé","given":"Francesca"},{"family":"Chollet","given":"Francois"},{"family":"Rong","given":"Frieda"},{"family":"Mishra","given":"Gaurav"},{"family":"Winata","given":"Genta Indra"},{"family":"Melo","given":"Gerard","dropping-particle":"de"},{"family":"Kruszewski","given":"Germán"},{"family":"Parascandolo","given":"Giambattista"},{"family":"Mariani","given":"Giorgio"},{"family":"Wang","given":"Gloria"},{"family":"Jaimovitch-López","given":"Gonzalo"},{"family":"Betz","given":"Gregor"},{"family":"Gur-Ari","given":"Guy"},{"family":"Galijasevic","given":"Hana"},{"family":"Kim","given":"Hannah"},{"family":"Rashkin","given":"Hannah"},{"family":"Hajishirzi","given":"Hannaneh"},{"family":"Mehta","given":"Harsh"},{"family":"Bogar","given":"Hayden"},{"family":"Shevlin","given":"Henry"},{"family":"Schütze","given":"Hinrich"},{"family":"Yakura","given":"Hiromu"},{"family":"Zhang","given":"Hongming"},{"family":"Wong","given":"Hugh Mee"},{"family":"Ng","given":"Ian"},{"family":"Noble","given":"Isaac"},{"family":"Jumelet","given":"Jaap"},{"family":"Geissinger","given":"Jack"},{"family":"Kernion","given":"Jackson"},{"family":"Hilton","given":"Jacob"},{"family":"Lee","given":"Jaehoon"},{"family":"Fisac","given":"Jaime Fernández"},{"family":"Simon","given":"James B."},{"family":"Koppel","given":"James"},{"family":"Zheng","given":"James"},{"family":"Zou","given":"James"},{"family":"Kocoń","given":"Jan"},{"family":"Thompson","given":"Jana"},{"family":"Wingfield","given":"Janelle"},{"family":"Kaplan","given":"Jared"},{"family":"Radom","given":"Jarema"},{"family":"Sohl-Dickstein","given":"Jascha"},{"family":"Phang","given":"Jason"},{"family":"Wei","given":"Jason"},{"family":"Yosinski","given":"Jason"},{"family":"Novikova","given":"Jekaterina"},{"family":"Bosscher","given":"Jelle"},{"family":"Marsh","given":"Jennifer"},{"family":"Kim","given":"Jeremy"},{"family":"Taal","given":"Jeroen"},{"family":"Engel","given":"Jesse"},{"family":"Alabi","given":"Jesujoba"},{"family":"Xu","given":"Jiacheng"},{"family":"Song","given":"Jiaming"},{"family":"Tang","given":"Jillian"},{"family":"Waweru","given":"Joan"},{"family":"Burden","given":"John"},{"family":"Miller","given":"John"},{"family":"Balis","given":"John U."},{"family":"Batchelder","given":"Jonathan"},{"family":"Berant","given":"Jonathan"},{"family":"Frohberg","given":"Jörg"},{"family":"Rozen","given":"Jos"},{"family":"Hernandez-Orallo","given":"Jose"},{"family":"Boudeman","given":"Joseph"},{"family":"Guerr","given":"Joseph"},{"family":"Jones","given":"Joseph"},{"family":"Tenenbaum","given":"Joshua B."},{"family":"Rule","given":"Joshua S."},{"family":"Chua","given":"Joyce"},{"family":"Kanclerz","given":"Kamil"},{"family":"Livescu","given":"Karen"},{"family":"Krauth","given":"Karl"},{"family":"Gopalakrishnan","given":"Karthik"},{"family":"Ignatyeva","given":"Katerina"},{"family":"Markert","given":"Katja"},{"family":"Dhole","given":"Kaustubh D."},{"family":"Gimpel","given":"Kevin"},{"family":"Omondi","given":"Kevin"},{"family":"Mathewson","given":"Kory"},{"family":"Chiafullo","given":"Kristen"},{"family":"Shkaruta","given":"Ksenia"},{"family":"Shridhar","given":"Kumar"},{"family":"McDonell","given":"Kyle"},{"family":"Richardson","given":"Kyle"},{"family":"Reynolds","given":"Laria"},{"family":"Gao","given":"Leo"},{"family":"Zhang","given":"Li"},{"family":"Dugan","given":"Liam"},{"family":"Qin","given":"Lianhui"},{"family":"Contreras-Ochando","given":"Lidia"},{"family":"Morency","given":"Louis-Philippe"},{"family":"Moschella","given":"Luca"},{"family":"Lam","given":"Lucas"},{"family":"Noble","given":"Lucy"},{"family":"Schmidt","given":"Ludwig"},{"family":"He","given":"Luheng"},{"family":"Colón","given":"Luis Oliveros"},{"family":"Metz","given":"Luke"},{"family":"Şenel","given":"Lütfi Kerem"},{"family":"Bosma","given":"Maarten"},{"family":"Sap","given":"Maarten"},{"family":"Hoeve","given":"Maartje","dropping-particle":"ter"},{"family":"Farooqi","given":"Maheen"},{"family":"Faruqui","given":"Manaal"},{"family":"Mazeika","given":"Mantas"},{"family":"Baturan","given":"Marco"},{"family":"Marelli","given":"Marco"},{"family":"Maru","given":"Marco"},{"family":"Quintana","given":"Maria Jose Ramírez"},{"family":"Tolkiehn","given":"Marie"},{"family":"Giulianelli","given":"Mario"},{"family":"Lewis","given":"Martha"},{"family":"Potthast","given":"Martin"},{"family":"Leavitt","given":"Matthew L."},{"family":"Hagen","given":"Matthias"},{"family":"Schubert","given":"Mátyás"},{"family":"Baitemirova","given":"Medina Orduna"},{"family":"Arnaud","given":"Melody"},{"family":"McElrath","given":"Melvin"},{"family":"Yee","given":"Michael A."},{"family":"Cohen","given":"Michael"},{"family":"Gu","given":"Michael"},{"family":"Ivanitskiy","given":"Michael"},{"family":"Starritt","given":"Michael"},{"family":"Strube","given":"Michael"},{"family":"Swędrowski","given":"Michał"},{"family":"Bevilacqua","given":"Michele"},{"family":"Yasunaga","given":"Michihiro"},{"family":"Kale","given":"Mihir"},{"family":"Cain","given":"Mike"},{"family":"Xu","given":"Mimee"},{"family":"Suzgun","given":"Mirac"},{"family":"Walker","given":"Mitch"},{"family":"Tiwari","given":"Mo"},{"family":"Bansal","given":"Mohit"},{"family":"Aminnaseri","given":"Moin"},{"family":"Geva","given":"Mor"},{"family":"Gheini","given":"Mozhdeh"},{"family":"T","given":"Mukund Varma"},{"family":"Peng","given":"Nanyun"},{"family":"Chi","given":"Nathan A."},{"family":"Lee","given":"Nayeon"},{"family":"Krakover","given":"Neta Gur-Ari"},{"family":"Cameron","given":"Nicholas"},{"family":"Roberts","given":"Nicholas"},{"family":"Doiron","given":"Nick"},{"family":"Martinez","given":"Nicole"},{"family":"Nangia","given":"Nikita"},{"family":"Deckers","given":"Niklas"},{"family":"Muennighoff","given":"Niklas"},{"family":"Keskar","given":"Nitish Shirish"},{"family":"Iyer","given":"Niveditha S."},{"family":"Constant","given":"Noah"},{"family":"Fiedel","given":"Noah"},{"family":"Wen","given":"Nuan"},{"family":"Zhang","given":"Oliver"},{"family":"Agha","given":"Omar"},{"family":"Elbaghdadi","given":"Omar"},{"family":"Levy","given":"Omer"},{"family":"Evans","given":"Owain"},{"family":"Casares","given":"Pablo Antonio Moreno"},{"family":"Doshi","given":"Parth"},{"family":"Fung","given":"Pascale"},{"family":"Liang","given":"Paul Pu"},{"family":"Vicol","given":"Paul"},{"family":"Alipoormolabashi","given":"Pegah"},{"family":"Liao","given":"Peiyuan"},{"family":"Liang","given":"Percy"},{"family":"Chang","given":"Peter"},{"family":"Eckersley","given":"Peter"},{"family":"Htut","given":"Phu Mon"},{"family":"Hwang","given":"Pinyu"},{"family":"Miłkowski","given":"Piotr"},{"family":"Patil","given":"Piyush"},{"family":"Pezeshkpour","given":"Pouya"},{"family":"Oli","given":"Priti"},{"family":"Mei","given":"Qiaozhu"},{"family":"Lyu","given":"Qing"},{"family":"Chen","given":"Qinlang"},{"family":"Banjade","given":"Rabin"},{"family":"Rudolph","given":"Rachel Etta"},{"family":"Gabriel","given":"Raefer"},{"family":"Habacker","given":"Rahel"},{"family":"Risco","given":"Ramon"},{"family":"Millière","given":"Raphaël"},{"family":"Garg","given":"Rhythm"},{"family":"Barnes","given":"Richard"},{"family":"Saurous","given":"Rif A."},{"family":"Arakawa","given":"Riku"},{"family":"Raymaekers","given":"Robbe"},{"family":"Frank","given":"Robert"},{"family":"Sikand","given":"Rohan"},{"family":"Novak","given":"Roman"},{"family":"Sitelew","given":"Roman"},{"family":"LeBras","given":"Ronan"},{"family":"Liu","given":"Rosanne"},{"family":"Jacobs","given":"Rowan"},{"family":"Zhang","given":"Rui"},{"family":"Salakhutdinov","given":"Ruslan"},{"family":"Chi","given":"Ryan"},{"family":"Lee","given":"Ryan"},{"family":"Stovall","given":"Ryan"},{"family":"Teehan","given":"Ryan"},{"family":"Yang","given":"Rylan"},{"family":"Singh","given":"Sahib"},{"family":"Mohammad","given":"Saif M."},{"family":"Anand","given":"Sajant"},{"family":"Dillavou","given":"Sam"},{"family":"Shleifer","given":"Sam"},{"family":"Wiseman","given":"Sam"},{"family":"Gruetter","given":"Samuel"},{"family":"Bowman","given":"Samuel R."},{"family":"Schoenholz","given":"Samuel S."},{"family":"Han","given":"Sanghyun"},{"family":"Kwatra","given":"Sanjeev"},{"family":"Rous","given":"Sarah A."},{"family":"Ghazarian","given":"Sarik"},{"family":"Ghosh","given":"Sayan"},{"family":"Casey","given":"Sean"},{"family":"Bischoff","given":"Sebastian"},{"family":"Gehrmann","given":"Sebastian"},{"family":"Schuster","given":"Sebastian"},{"family":"Sadeghi","given":"Sepideh"},{"family":"Hamdan","given":"Shadi"},{"family":"Zhou","given":"Sharon"},{"family":"Srivastava","given":"Shashank"},{"family":"Shi","given":"Sherry"},{"family":"Singh","given":"Shikhar"},{"family":"Asaadi","given":"Shima"},{"family":"Gu","given":"Shixiang Shane"},{"family":"Pachchigar","given":"Shubh"},{"family":"Toshniwal","given":"Shubham"},{"family":"Upadhyay","given":"Shyam"},{"family":"Shyamolima","given":""},{"family":"Debnath","given":""},{"family":"Shakeri","given":"Siamak"},{"family":"Thormeyer","given":"Simon"},{"family":"Melzi","given":"Simone"},{"family":"Reddy","given":"Siva"},{"family":"Makini","given":"Sneha Priscilla"},{"family":"Lee","given":"Soo-Hwan"},{"family":"Torene","given":"Spencer"},{"family":"Hatwar","given":"Sriharsha"},{"family":"Dehaene","given":"Stanislas"},{"family":"Divic","given":"Stefan"},{"family":"Ermon","given":"Stefano"},{"family":"Biderman","given":"Stella"},{"family":"Lin","given":"Stephanie"},{"family":"Prasad","given":"Stephen"},{"family":"Piantadosi","given":"Steven T."},{"family":"Shieber","given":"Stuart M."},{"family":"Misherghi","given":"Summer"},{"family":"Kiritchenko","given":"Svetlana"},{"family":"Mishra","given":"Swaroop"},{"family":"Linzen","given":"Tal"},{"family":"Schuster","given":"Tal"},{"family":"Li","given":"Tao"},{"family":"Yu","given":"Tao"},{"family":"Ali","given":"Tariq"},{"family":"Hashimoto","given":"Tatsu"},{"family":"Wu","given":"Te-Lin"},{"family":"Desbordes","given":"Théo"},{"family":"Rothschild","given":"Theodore"},{"family":"Phan","given":"Thomas"},{"family":"Wang","given":"Tianle"},{"family":"Nkinyili","given":"Tiberius"},{"family":"Schick","given":"Timo"},{"family":"Kornev","given":"Timofei"},{"family":"Tunduny","given":"Titus"},{"family":"Gerstenberg","given":"Tobias"},{"family":"Chang","given":"Trenton"},{"family":"Neeraj","given":"Trishala"},{"family":"Khot","given":"Tushar"},{"family":"Shultz","given":"Tyler"},{"family":"Shaham","given":"Uri"},{"family":"Misra","given":"Vedant"},{"family":"Demberg","given":"Vera"},{"family":"Nyamai","given":"Victoria"},{"family":"Raunak","given":"Vikas"},{"family":"Ramasesh","given":"Vinay"},{"family":"Prabhu","given":"Vinay Uday"},{"family":"Padmakumar","given":"Vishakh"},{"family":"Srikumar","given":"Vivek"},{"family":"Fedus","given":"William"},{"family":"Saunders","given":"William"},{"family":"Zhang","given":"William"},{"family":"Vossen","given":"Wout"},{"family":"Ren","given":"Xiang"},{"family":"Tong","given":"Xiaoyu"},{"family":"Zhao","given":"Xinran"},{"family":"Wu","given":"Xinyi"},{"family":"Shen","given":"Xudong"},{"family":"Yaghoobzadeh","given":"Yadollah"},{"family":"Lakretz","given":"Yair"},{"family":"Song","given":"Yangqiu"},{"family":"Bahri","given":"Yasaman"},{"family":"Choi","given":"Yejin"},{"family":"Yang","given":"Yichi"},{"family":"Hao","given":"Yiding"},{"family":"Chen","given":"Yifu"},{"family":"Belinkov","given":"Yonatan"},{"family":"Hou","given":"Yu"},{"family":"Hou","given":"Yufang"},{"family":"Bai","given":"Yuntao"},{"family":"Seid","given":"Zachary"},{"family":"Zhao","given":"Zhuoye"},{"family":"Wang","given":"Zijian"},{"family":"Wang","given":"Zijie J."},{"family":"Wang","given":"Zirui"},{"family":"Wu","given":"Ziyi"}],"citation-key":"srivastavaImitationGameQuantifying2023","DOI":"10.48550/arXiv.2206.04615","issued":{"date-parts":[["2023",6,12]]},"number":"arXiv:2206.04615","publisher":"arXiv","source":"arXiv.org","title":"Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models","title-short":"Beyond the Imitation Game","type":"article","URL":"http://arxiv.org/abs/2206.04615"},
  {"id":"strubellEnergyPolicyConsiderations2019","abstract":"Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Strubell","given":"Emma"},{"family":"Ganesh","given":"Ananya"},{"family":"McCallum","given":"Andrew"}],"citation-key":"strubellEnergyPolicyConsiderations2019","container-title":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","DOI":"10.18653/v1/P19-1355","editor":[{"family":"Korhonen","given":"Anna"},{"family":"Traum","given":"David"},{"family":"Màrquez","given":"Lluís"}],"event-place":"Florence, Italy","event-title":"ACL 2019","issued":{"date-parts":[["2019",7]]},"page":"3645–3650","publisher":"Association for Computational Linguistics","publisher-place":"Florence, Italy","source":"ACLWeb","title":"Energy and Policy Considerations for Deep Learning in NLP","type":"paper-conference","URL":"https://aclanthology.org/P19-1355/"},
  {"id":"subburajFuzzySystemBased2025","abstract":"Simulated by nature’s evolution, numerous evolutionary algorithms had been proposed. These algorithms perform better for a particular problem domain and extensive parameter fine tuning and adaptations are required in optimizing problems of varied domain. This paper aims to develop robust and self-adaptive memetic algorithm by combining Differential Evolution based algorithm, a popular population based global search method with the Controlled Local search procedure to solve multi-objective optimization problems. Memetic Algorithm is an enhanced evolutionary algorithm, it combines global search method with local search techniques for faster convergence. Memetic algorithm improves both exploration and exploitation, preventing premature convergence and also refines the current best solutions efficiently. Proposed algorithm is named as Fuzzy based Memetic Algorithm using Diversity control (F-MAD). In F-MAD, population diversity is controlled through the control parameters self-adaptation of Differential Evolution algorithm (DE) such as, crossover rate and scaling factor by using two fuzzy systems. A controlled local search procedure is adapted for guiding convergence process thus balancing explore-exploit cycle. The control parameter self-adaptation and enhanced selection method with controlled local search method aid population diversity control in decision space and attaining optimal solutions with uniform distribution in terms of diversity and convergence metrics in objective space. These characteristics help the proposed method suitable to be extended to different application domain without the need of trial-and-error fine tuning of the parameters. The performance is tested through standard benchmark test problems-CEC 2009 test problems and DTLZ test problem and further validated through performance metrics and statistical test. It is compared with popular optimization algorithms and experiment results indicate that F-MAD perform well than State of-The-Art (SOTA) algorithms taken for comparison. F-MAD algorithm attains better results for 8 out of 10 CEC 2009 test problems (UF1-UF10) when compared to 20 other algorithms taken for comparison. For DTLZ problems, F-MAD attains better results for ALL 7 problems (DTLZ 1-DTLZ7) when compared to 8 other SOTA algorithms. The performance is further evaluated using Friedman rank test and the proposed F-MAD significantly outperformed other algorithms.","accessed":{"date-parts":[["2025",6,12]]},"author":[{"family":"Subburaj","given":"Brindha"},{"family":"Miruna Joe Amali","given":"S."}],"citation-key":"subburajFuzzySystemBased2025","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-025-89289-2","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2025",2,17]]},"language":"en","license":"2025 The Author(s)","page":"5735","publisher":"Nature Publishing Group","source":"www.nature.com","title":"A fuzzy system based self-adaptive memetic algorithm using population diversity control for evolutionary multi-objective optimization","type":"article-journal","URL":"https://www.nature.com/articles/s41598-025-89289-2","volume":"15"},
  {"id":"sydenhamHandbookMeasuringSystem2005","citation-key":"sydenhamHandbookMeasuringSystem2005","editor":[{"family":"Sydenham","given":"Peter H."},{"family":"Thorn","given":"Richard"}],"event-place":"Chichester","ISBN":"978-0-470-02143-9","issued":{"date-parts":[["2005"]]},"language":"en","publisher":"Wiley","publisher-place":"Chichester","source":"K10plus ISBN","title":"Handbook of measuring system design","type":"book"},
  {"id":"TorchcudaPyTorch24","accessed":{"date-parts":[["2024",10,8]]},"citation-key":"TorchcudaPyTorch24","title":"torch.cuda — PyTorch 2.4 documentation","type":"webpage","URL":"https://pytorch.org/docs/stable/cuda.html"},
  {"id":"vanderplasPythonDataScience2016","abstract":"For many researchers, Python is a first-class tool mainly because of its libraries for storing, manipulating, and gaining insight from data. Several resources exist for individual pieces of this data science stack, but only with the Python Data Science Handbook do you get them all—IPython, NumPy, Pandas, Matplotlib, Scikit-Learn, and other related tools.Working scientists and data crunchers familiar with reading and writing Python code will find this comprehensive desk reference ideal for tackling day-to-day issues: manipulating, transforming, and cleaning data; visualizing different types of data; and using data to build statistical or machine learning models. Quite simply, this is the must-have reference for scientific computing in Python.With this handbook, you’ll learn how to use:IPython and Jupyter: provide computational environments for data scientists using PythonNumPy: includes the ndarray for efficient storage and manipulation of dense data arrays in PythonPandas: features the DataFrame for efficient storage and manipulation of labeled/columnar data in PythonMatplotlib: includes capabilities for a flexible range of data visualizations in PythonScikit-Learn: for efficient and clean Python implementations of the most important and established machine learning algorithms","author":[{"family":"VanderPlas","given":"Jake"}],"citation-key":"vanderplasPythonDataScience2016","ISBN":"978-1-4919-1214-0","issued":{"date-parts":[["2016",11,21]]},"language":"en","number-of-pages":"548","publisher":"O'Reilly Media, Inc.","source":"Google Books","title":"Python Data Science Handbook: Essential Tools for Working with Data","title-short":"Python Data Science Handbook","type":"book","URL":"https://books.google.es/books?hl=es&lr=&id=xYmNDQAAQBAJ&oi=fnd&pg=PR2&dq=Python+Data+Science+Handbook&ots=Xs9Rj3qj-M&sig=f5K5ixzKjH7pc2Uo2IYW9jrPNI8#v=onepage&q=Python%20Data%20Science%20Handbook&f=false"},
  {"id":"wangDatasetDistillation2020","abstract":"Model distillation aims to distill the knowledge of a complex model into a simpler one. In this paper, we consider an alternative formulation called dataset distillation: we keep the model fixed and instead attempt to distill the knowledge from a large training dataset into a small one. The idea is to synthesize a small number of data points that do not need to come from the correct data distribution, but will, when given to the learning algorithm as training data, approximate the model trained on the original data. For example, we show that it is possible to compress 60,000 MNIST training images into just 10 synthetic distilled images (one per class) and achieve close to original performance with only a few gradient descent steps, given a fixed network initialization. We evaluate our method in various initialization settings and with different learning objectives. Experiments on multiple datasets show the advantage of our approach compared to alternative methods.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Wang","given":"Tongzhou"},{"family":"Zhu","given":"Jun-Yan"},{"family":"Torralba","given":"Antonio"},{"family":"Efros","given":"Alexei A."}],"citation-key":"wangDatasetDistillation2020","DOI":"10.48550/arXiv.1811.10959","issued":{"date-parts":[["2020",2,24]]},"number":"arXiv:1811.10959","publisher":"arXiv","source":"arXiv.org","title":"Dataset Distillation","type":"article","URL":"http://arxiv.org/abs/1811.10959"},
  {"id":"wangImprovedCertifiedDefenses2022","abstract":"Data poisoning attacks aim at manipulating model behaviors through distorting training data. Previously, an aggregation-based certified defense, Deep Partition Aggregation (DPA), was proposed to mitigate this threat. DPA predicts through an aggregation of base classifiers trained on disjoint subsets of data, thus restricting its sensitivity to dataset distortions. In this work, we propose an improved certified defense against general poisoning attacks, namely Finite Aggregation. In contrast to DPA, which directly splits the training set into disjoint subsets, our method first splits the training set into smaller disjoint subsets and then combines duplicates of them to build larger (but not disjoint) subsets for training base classifiers. This reduces the worst-case impacts of poison samples and thus improves certified robustness bounds. In addition, we offer an alternative view of our method, bridging the designs of deterministic and stochastic aggregation-based certified defenses. Empirically, our proposed Finite Aggregation consistently improves certificates on MNIST, CIFAR-10, and GTSRB, boosting certified fractions by up to 3.05%, 3.87% and 4.77%, respectively, while keeping the same clean accuracies as DPA's, effectively establishing a new state of the art in (pointwise) certified robustness against data poisoning.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Wang","given":"Wenxiao"},{"family":"Levine","given":"Alexander"},{"family":"Feizi","given":"Soheil"}],"citation-key":"wangImprovedCertifiedDefenses2022","DOI":"10.48550/arXiv.2202.02628","issued":{"date-parts":[["2022",7,14]]},"number":"arXiv:2202.02628","publisher":"arXiv","source":"arXiv.org","title":"Improved Certified Defenses against Data Poisoning with (Deterministic) Finite Aggregation","type":"article","URL":"http://arxiv.org/abs/2202.02628"},
  {"id":"weidmanDeepLearningScratch2019","author":[{"family":"Weidman","given":"S."}],"citation-key":"weidmanDeepLearningScratch2019","ISBN":"978-1-4920-4141-2","issued":{"date-parts":[["2019"]]},"publisher":"O'Reilly Media, Incorporated","title":"Deep Learning from Scratch: Building with Python from First Principles","type":"book","URL":"https://books.google.es/books?id=PRSCwwEACAAJ"},
  {"id":"WhatCloudRun","accessed":{"date-parts":[["2025",2,25]]},"citation-key":"WhatCloudRun","language":"en","title":"What is Cloud Run | Cloud Run Documentation","type":"webpage","URL":"https://cloud.google.com/run/docs/overview/what-is-cloud-run"},
  {"id":"wickramarachchiKnowledgeGraphsDriving2024","abstract":"In the era of Generative AI, Neurosymbolic AI is emerging as a powerful approach for tasks spanning from perception to cognition. The use of Neurosymbolic AI has been shown to achieve enhanced capabilities, including improved grounding, alignment, explainability, and reliability. However, due to its nascent stage, there is a lack of widely available real-world benchmark datasets tailored to Neurosymbolic AI tasks. To address this gap and support the evaluation of current and future methods, we introduce DSceneKG -- a suite of knowledge graphs of driving scenes built from real-world, high-quality scenes from multiple open autonomous driving datasets. In this article, we detail the construction process of DSceneKG and highlight its application in seven different tasks. DSceneKG is publicly accessible at: https://github.com/ruwantw/DSceneKG","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Wickramarachchi","given":"Ruwan"},{"family":"Henson","given":"Cory"},{"family":"Sheth","given":"Amit"}],"citation-key":"wickramarachchiKnowledgeGraphsDriving2024","DOI":"10.48550/arXiv.2411.03225","issued":{"date-parts":[["2024",11,7]]},"number":"arXiv:2411.03225","publisher":"arXiv","source":"arXiv.org","title":"Knowledge Graphs of Driving Scenes to Empower the Emerging Capabilities of Neurosymbolic AI","type":"article","URL":"http://arxiv.org/abs/2411.03225"},
  {"id":"wilsonAsymptoticPropertiesNearest1972","abstract":"The convergence properties of a nearest neighbor rule that uses an editing procedure to reduce the number of preclassified samples and to improve the performance of the rule are developed. Editing of the preclassified samples using the three-nearest neighbor rule followed by classification using the single-nearest neighbor rule with the remaining preclassified samples appears to produce a decision procedure whose risk approaches the Bayes' risk quite closely in many problems with only a few preclassified samples. The asymptotic risk of the nearest neighbor rules and the nearest neighbor rules using edited preclassified samples is calculated for several problems.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Wilson","given":"Dennis L."}],"citation-key":"wilsonAsymptoticPropertiesNearest1972","container-title":"IEEE Transactions on Systems, Man, and Cybernetics","DOI":"10.1109/TSMC.1972.4309137","ISSN":"2168-2909","issue":"3","issued":{"date-parts":[["1972",7]]},"page":"408-421","source":"IEEE Xplore","title":"Asymptotic Properties of Nearest Neighbor Rules Using Edited Data","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/4309137","volume":"SMC-2"},
  {"id":"WN18DatasetDGL25","accessed":{"date-parts":[["2025",10,8]]},"citation-key":"WN18DatasetDGL25","title":"WN18Dataset — DGL 2.5 documentation","type":"webpage","URL":"https://www.dgl.ai/dgl_docs/generated/dgl.data.WN18Dataset.html"},
  {"id":"woernerComprehensiveEasytouseMultidomain2025","abstract":"While the field of medical image analysis has undergone a transformative shift with the integration of machine learning techniques, the main challenge of these techniques is often the scarcity of large, diverse, and well-annotated datasets. Medical images vary in format, size, and other parameters and therefore require extensive preprocessing and standardization, for usage in machine learning. Addressing these challenges, we introduce the Medical Imaging Meta-Dataset (MedIMeta), a novel multi-domain, multi-task meta-dataset. MedIMeta contains 19 medical imaging datasets spanning 10 different domains and encompassing 54 distinct medical tasks, all of which are standardized to the same format and readily usable in PyTorch or other ML frameworks. We perform a technical validation of MedIMeta, demonstrating its utility through fully supervised and cross-domain few-shot learning baselines.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Woerner","given":"Stefano"},{"family":"Jaques","given":"Arthur"},{"family":"Baumgartner","given":"Christian F."}],"citation-key":"woernerComprehensiveEasytouseMultidomain2025","container-title":"Scientific Data","container-title-short":"Sci Data","DOI":"10.1038/s41597-025-04866-4","ISSN":"2052-4463","issue":"1","issued":{"date-parts":[["2025",4,19]]},"language":"en","license":"2025 The Author(s)","page":"666","publisher":"Nature Publishing Group","source":"www.nature.com","title":"A comprehensive and easy-to-use multi-domain multi-task medical imaging meta-dataset","type":"article-journal","URL":"https://www.nature.com/articles/s41597-025-04866-4","volume":"12"},
  {"id":"zhaDatacentricArtificialIntelligence2023","abstract":"Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI. The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages of the data lifecycle. We hope it can help the readers efficiently grasp a broad picture of this field, and equip them with the techniques and further research ideas to systematically engineer data for building AI systems. A companion list of data-centric AI resources will be regularly updated on https://github.com/daochenzha/data-centric-AI","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Zha","given":"Daochen"},{"family":"Bhat","given":"Zaid Pervaiz"},{"family":"Lai","given":"Kwei-Herng"},{"family":"Yang","given":"Fan"},{"family":"Jiang","given":"Zhimeng"},{"family":"Zhong","given":"Shaochen"},{"family":"Hu","given":"Xia"}],"citation-key":"zhaDatacentricArtificialIntelligence2023","DOI":"10.48550/arXiv.2303.10158","issued":{"date-parts":[["2023",6,11]]},"number":"arXiv:2303.10158","publisher":"arXiv","source":"arXiv.org","title":"Data-centric Artificial Intelligence: A Survey","title-short":"Data-centric Artificial Intelligence","type":"article","URL":"http://arxiv.org/abs/2303.10158"},
  {"id":"zhangNeuroSymbolicAIExplainability2024","abstract":"Explainability is an essential reason limiting the application of neural networks in many vital fields. Although neuro-symbolic AI hopes to enhance the overall explainability by leveraging the transparency of symbolic learning, the results are less evident than imagined. This article proposes a classification for explainability by considering both model design and behavior of 191 studies from 2013, focusing on neuro-symbolic AI, hoping to inspire scholars who want to understand the explainability of neuro-symbolic AI. Precisely, we classify them into five categories by considering whether the form of bridging the representation differences is readable as their design factor, if there are representation differences between neural networks and symbolic logic learning, and whether a model decision or prediction process is understandable as their behavior factor: implicit intermediate representations and implicit prediction, partially explicit intermediate representations and partially explicit prediction, explicit intermediate representations or explicit prediction, explicit intermediate representation and explicit prediction, unified representation and explicit prediction. We also analyzed the research trends and three significant challenges: unified representations, explainability and transparency, and sufficient cooperation from neural networks and symbolic learning. Finally, we put forward suggestions for future research in three aspects: unified representations, enhancing model explainability, ethical considerations, and social impact.","accessed":{"date-parts":[["2025",10,8]]},"author":[{"family":"Zhang","given":"Xin"},{"family":"Sheng","given":"Victor S."}],"citation-key":"zhangNeuroSymbolicAIExplainability2024","DOI":"10.48550/arXiv.2411.04383","issued":{"date-parts":[["2024",11,7]]},"number":"arXiv:2411.04383","publisher":"arXiv","source":"arXiv.org","title":"Neuro-Symbolic AI: Explainability, Challenges, and Future Trends","title-short":"Neuro-Symbolic AI","type":"article","URL":"http://arxiv.org/abs/2411.04383"},
  {"id":"zhaoDatasetCondensationGradient2021","abstract":"As the state-of-the-art machine learning methods in many fields rely on larger datasets, storing datasets and training models on them become significantly more expensive. This paper proposes a training set synthesis technique for data-efficient learning, called Dataset Condensation, that learns to condense large dataset into a small set of informative synthetic samples for training deep neural networks from scratch. We formulate this goal as a gradient matching problem between the gradients of deep neural network weights that are trained on the original and our synthetic data. We rigorously evaluate its performance in several computer vision benchmarks and demonstrate that it significantly outperforms the state-of-the-art methods. Finally we explore the use of our method in continual learning and neural architecture search and report promising gains when limited memory and computations are available.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Zhao","given":"Bo"},{"family":"Mopuri","given":"Konda Reddy"},{"family":"Bilen","given":"Hakan"}],"citation-key":"zhaoDatasetCondensationGradient2021","DOI":"10.48550/arXiv.2006.05929","issued":{"date-parts":[["2021",3,8]]},"number":"arXiv:2006.05929","publisher":"arXiv","source":"arXiv.org","title":"Dataset Condensation with Gradient Matching","type":"article","URL":"http://arxiv.org/abs/2006.05929"},
  {"id":"zhaoReviewConvolutionalNeural2024","abstract":"In computer vision, a series of exemplary advances have been made in several areas involving image classification, semantic segmentation, object detection, and image super-resolution reconstruction with the rapid development of deep convolutional neural network (CNN). The CNN has superior features for autonomous learning and expression, and feature extraction from original input data can be realized by means of training CNN models that match practical applications. Due to the rapid progress in deep learning technology, the structure of CNN is becoming more and more complex and diverse. Consequently, it gradually replaces the traditional machine learning methods. This paper presents an elementary understanding of CNN components and their functions, including input layers, convolution layers, pooling layers, activation functions, batch normalization, dropout, fully connected layers, and output layers. On this basis, this paper gives a comprehensive overview of the past and current research status of the applications of CNN models in computer vision fields, e.g., image classification, object detection, and video prediction. In addition, we summarize the challenges and solutions of the deep CNN, and future research directions are also discussed.","author":[{"family":"Zhao","given":"Xia"},{"family":"Wang","given":"Limin"},{"family":"Zhang","given":"Yufei"},{"family":"Han","given":"Xuming"},{"family":"Deveci","given":"Muhammet"},{"family":"Parmar","given":"Milan"}],"citation-key":"zhaoReviewConvolutionalNeural2024","container-title":"Artificial Intelligence Review","container-title-short":"Artif Intell Rev","DOI":"10.1007/s10462-024-10721-6","ISSN":"1573-7462","issue":"4","issued":{"date-parts":[["2024",3,23]]},"language":"en","page":"99","source":"Springer Link","title":"A review of convolutional neural networks in computer vision","type":"article-journal","URL":"https://doi.org/10.1007/s10462-024-10721-6","volume":"57"},
  {"id":"zhouDistilledOneShotFederated2021","abstract":"Current federated learning algorithms take tens of communication rounds transmitting unwieldy model weights under ideal circumstances and hundreds when data is poorly distributed. Inspired by recent work on dataset distillation and distributed one-shot learning, we propose Distilled One-Shot Federated Learning (DOSFL) to significantly reduce the communication cost while achieving comparable performance. In just one round, each client distills their private dataset, sends the synthetic data (e.g. images or sentences) to the server, and collectively trains a global model. The distilled data look like noise and are only useful to the specific model weights, i.e., become useless after the model updates. With this weight-less and gradient-less design, the total communication cost of DOSFL is up to three orders of magnitude less than FedAvg while preserving between 93% to 99% performance of a centralized counterpart. Afterwards, clients could switch to traditional methods such as FedAvg to finetune the last few percent to fit personalized local models with local datasets. Through comprehensive experiments, we show the accuracy and communication performance of DOSFL on both vision and language tasks with different models including CNN, LSTM, Transformer, etc. We demonstrate that an eavesdropping attacker cannot properly train a good model using the leaked distilled data, without knowing the initial model weights. DOSFL serves as an inexpensive method to quickly converge on a performant pre-trained model with less than 0.1% communication cost of traditional methods.","accessed":{"date-parts":[["2025",6,14]]},"author":[{"family":"Zhou","given":"Yanlin"},{"family":"Pu","given":"George"},{"family":"Ma","given":"Xiyao"},{"family":"Li","given":"Xiaolin"},{"family":"Wu","given":"Dapeng"}],"citation-key":"zhouDistilledOneShotFederated2021","DOI":"10.48550/arXiv.2009.07999","issued":{"date-parts":[["2021",6,6]]},"number":"arXiv:2009.07999","publisher":"arXiv","source":"arXiv.org","title":"Distilled One-Shot Federated Learning","type":"article","URL":"http://arxiv.org/abs/2009.07999"}
]
