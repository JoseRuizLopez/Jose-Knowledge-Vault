links: [[102 - no-TFM]] 

## Parte simb√≥lica en un modelo neurosimb√≥lico

En general, el componente simb√≥lico:
- **Representa conocimiento expl√≠cito** (conceptos, relaciones, reglas l√≥gicas).
- **Permite razonar o verificar consistencia** de las predicciones neuronales.
- **Act√∫a como gu√≠a o regulador** del aprendizaje profundo.

Es decir, es **todo lo que no se aprende directamente de los datos**, sino que viene de **estructura conceptual o conocimiento experto**.  
En este caso, eso incluye desde un **grafo de conocimiento (KG)** hasta un **sistema de reglas o restricciones** sobre c√≥mo deber√≠an comportarse los objetos y sus relaciones en una escena.

---

## Niveles de la parte simb√≥lica

### üîπ Nivel 1 ‚Äî _Representaci√≥n simb√≥lica del conocimiento_
Aqu√≠ se define **qu√© sabes del mundo**, y lo formalizas. 

El DL detecta objetos y relaciones, pero se define un **grafo de conocimiento (KG)** que describe:
- Qu√© entidades existen (`Persona`, `Coche`, `Edificio`, `Sem√°foro`...)
- Qu√© relaciones son posibles (`est√°_cerca_de`, `conduce`, `entra_en`, `parte_de`...)
- Qu√© tipos de relaciones no son v√°lidas (`Persona dentro de Coche` s√≠, pero `Coche dentro de Persona` no). 

üîß Ejemplo:
`Regla 1: "Si un objeto es Persona y otro es Coche, la relaci√≥n v√°lida es 'conduce' o 'entra_en', pero no 'parte_de'." Regla 2: "Si un objeto es Edificio, puede tener relaci√≥n 'parte_de' con Ciudad."`

üìò T√©cnicamente, esto se puede almacenar como:
- Un **ontolog√≠a [[OWL]]/[[RDF]]** (para razonamiento l√≥gico formal).
- Un **Neo4j graph** (si priorizas consultas estructuradas).
- Un **diccionario Python + reglas simb√≥licas** (m√°s simple, pero suficiente para un prototipo).

---

### üîπ Nivel 2 ‚Äî _Alineaci√≥n sem√°ntica entre DL y KG_
La red neuronal detecta ‚Äúcosas‚Äù (perros, coches, sem√°foros...), pero **esas detecciones deben alinearse con conceptos simb√≥licos** del KG.

Esto implica:
1. Crear un **mapeo entre labels neuronales** (provenientes del dataset visual) **y nodos del grafo simb√≥lico**. 
> ¬øSe deber√≠a usar un embeding sem√°ntico/tabla de equivalencias para alinear autom√°ticamente t√©rminos similares para resolver la ambig√ºedad posible en el mapeo??
2. Traducir las salidas de la red (por ejemplo, tripletas ‚ÄúPersona ‚Äì junto_a ‚Äì Coche‚Äù) a nodos y aristas en un grafo sem√°ntico.
3. Verificar si esas relaciones **tienen sentido seg√∫n el conocimiento simb√≥lico**.

üîß Ejemplo:
> El modelo detecta ‚ÄúCoche sobre Persona‚Äù ‚Üí la parte simb√≥lica verifica que **esa relaci√≥n no es coherente** ‚Üí puede marcarla como inconsistente o corregirla.

üìò Aqu√≠ entra el razonamiento simb√≥lico:  
usando l√≥gicas tipo **Datalog, Prolog, [[OWL]] Reasoner** o incluso comprobaciones heur√≠sticas, puedes **detectar contradicciones o anomal√≠as**.

---
### üîπ Nivel 3 ‚Äî _Razonamiento y explicabilidad simb√≥lica_
El paso final es **usar ese conocimiento simb√≥lico para razonar o explicar**.

Esto puede adoptar tres formas:
#### (a) Verificaci√≥n / consistencia
Compruebas si las relaciones detectadas son v√°lidas:

> ‚ÄúEl sistema detect√≥ una persona conduciendo un coche, lo cual es coherente con las reglas del conocimiento.‚Äù
#### (b) Inferencia / enriquecimiento
Generas nuevas relaciones a partir del conocimiento:

> ‚ÄúSi un objeto es sem√°foro y est√° en rojo, infiero que los coches cercanos deber√≠an estar detenidos.‚Äù
#### (c) Explicaci√≥n
Usas el grafo simb√≥lico para **justificar** lo que el modelo visual predijo:

> ‚ÄúClasifiqu√© esto como una calle porque hay coches, peatones y sem√°foros alineados.‚Äù
---
## üß© 3. C√≥mo interact√∫an parte neuronal y simb√≥lica
Se podr√≠a entender como **dos cerebros colaborando**:

| Parte                       | Funci√≥n      | Ejemplo                                                                |
| --------------------------- | ------------ | ---------------------------------------------------------------------- |
| **Neuronal (DL)**           | Percepci√≥n   | ‚ÄúVeo un coche, una persona y un sem√°foro.‚Äù                             |
| **Simb√≥lica (KG + reglas)** | Razonamiento | ‚ÄúUn coche y una persona pueden estar juntos si la persona lo conduce.‚Äù |
| **Neuro-simb√≥lica**         | Integraci√≥n  | Ajusta predicciones seg√∫n conocimiento, o explica resultados.          |

üìò Puedes visualizarlo como un pipeline:
`Imagen ‚Üí CNN/Transformer (detector) ‚Üí Scene Graph ‚Üí Alineaci√≥n con KG ‚Üí Razonamiento simb√≥lico`

La parte simb√≥lica empieza **a partir del Scene Graph**, y es la que le da **sentido sem√°ntico y explicabilidad estructural**.

---
## ‚öôÔ∏è 4. C√≥mo implementarlo (opciones pr√°cticas)

Dependiendo del enfoque y tiempo que tengas, hay varios niveles de profundidad:

| Nivel    | Herramienta / Enfoque                       | Dificultad | Qu√© aporta                                           |
| -------- | ------------------------------------------- | ---------- | ---------------------------------------------------- |
| B√°sico   | Diccionario + comprobaci√≥n l√≥gica en Python | üü¢F√°cil    | Verificaci√≥n b√°sica de relaciones v√°lidas            |
| Medio    | Neo4j o [[RDF]] + SPARQL                    | üü†Media    | Consultas estructuradas y reglas declarativas        |
| Avanzado | [[OWL]] Reasoner / Prolog / Datalog         | üî¥Alta     | Razonamiento l√≥gico complejo e inferencia autom√°tica |

---
## üß≠ 5. C√≥mo explic√°rselo a Siham Tabik

> ‚ÄúLa parte simb√≥lica de mi TFM ser√° el m√≥dulo que represente y razone sobre el conocimiento. Mi idea es dise√±ar un grafo de conocimiento con las entidades y relaciones v√°lidas entre objetos de la escena.  
> Este grafo servir√° tanto para verificar la coherencia de las relaciones detectadas por el modelo visual como para generar explicaciones estructuradas del tipo ‚Äòpor qu√© se ha clasificado as√≠‚Äô.  
> Adem√°s, me gustar√≠a estudiar c√≥mo integrar parte de ese conocimiento como restricciones suaves durante el entrenamiento, siguiendo la l√≠nea de [[X-NeSyL]].‚Äù

Esto conecta directamente con el marco de Siham y con los papers (EXPLANet, SHAP-Backprop, Semantic Loss...).

---
## üß± 6. En resumen

| Rol             | Qu√© hace la parte simb√≥lica                                   |
| --------------- | ------------------------------------------------------------- |
| **Representar** | Define un modelo conceptual del mundo (KG, reglas, ontolog√≠a) |
| **Verificar**   | Comprueba que las predicciones neuronales sean coherentes     |
| **Inferir**     | Deduce relaciones adicionales basadas en reglas               |
| **Explicar**    | Justifica decisiones con conocimiento expl√≠cito               |
| **Guiar**       | (Opcional) Aporta restricciones o feedback al entrenamiento   |



---
tags:
	#Index #no-TFM