
[[Parte Simbolica]]
# ğŸ§  GuÃ­a para la ReuniÃ³n con Siham Tabik (TFM Neuro-SimbÃ³lico)

**Autor:** JosÃ© Ruiz LÃ³pez  
**MÃ¡ster:** DATCOM UGR (modalidad parcial)  
**Propuesta de TFM:**  
> *Modelos neurosimbÃ³licos para el reconocimiento semÃ¡ntico de escenas mediante integraciÃ³n de grafos de conocimiento y redes neuronales profundas.*

---
## ğŸ¯ Objetivo de la reuniÃ³n

1. Confirmar si Siham Tabik puede ser tutora del TFM.  
2. Validar el **alcance tÃ©cnico** y **dominio** del proyecto.  
3. Alinear la propuesta con el enfoque de su grupo **[[X-NeSyL]]**.  
4. Obtener **orientaciÃ³n bibliogrÃ¡fica y metodolÃ³gica**.  

---
## ğŸ§­ Estructura sugerida (20â€“30 min)

### 1. IntroducciÃ³n breve (2â€“3 min)
> â€œGracias por su tiempo.  
> Me interesa trabajar en la intersecciÃ³n entre visiÃ³n por computador, conocimiento simbÃ³lico y explicabilidad.  
> Creo que su enfoque en [[X-NeSyL]] es ideal para aprender a integrar conocimiento estructurado con aprendizaje profundo.â€

---
### 2. PresentaciÃ³n de la propuesta (5 min)

#### ğŸ§© Idea general
Ir mÃ¡s allÃ¡ de la detecciÃ³n de objetos, buscando **interpretar escenas completas** mediante la integraciÃ³n:
- *Deep Learning (DL)* â†’ percepciÃ³n visual.  
- *Knowledge Graphs (KG)* â†’ razonamiento simbÃ³lico.  

#### âš™ï¸ Enfoque tÃ©cnico
1. **ExtracciÃ³n de scene graphs** desde la imagen.  
2. **AlineaciÃ³n con un KG** de dominio.  
3. **Razonamiento simbÃ³lico** (verificaciÃ³n, inferencia, explicabilidad).  

#### ğŸ’¡ Valor aÃ±adido
- Explicaciones estructuradas (â€œpor quÃ© ve lo que veâ€).  
- EvaluaciÃ³n de consistencia lÃ³gica.  
- IA mÃ¡s confiable y transparente.

---
### 3. Preguntas clave para discutir (10â€“15 min)
1. Â¿QuÃ© dominio recomienda usar (trÃ¡fico, urbano, patrimonio)?  
2. Â¿Conviene centrarse en toda la integraciÃ³n DL+KG+razonamiento o empezar con una parte (p. ej. alineaciÃ³n)?  
3. Â¿QuÃ© mÃ©tricas considera mÃ¡s adecuadas para medir explicabilidad simbÃ³lica?  
4. Â¿Cree posible adaptar la metodologÃ­a **[[X-NeSyL]]** al reconocimiento de relaciones espaciales o funcionales?

---
### 4. Cuestiones prÃ¡cticas (5 min)
- Acceso a datasets o frameworks de **MonuMAI / [[X-NeSyL]]**.  
- BibliografÃ­a o papers recomendados.  
- Calendario sugerido si empiezo este aÃ±o.  
- Posibilidad de asistir como oyente a alguna clase/seminario.

---
## ğŸ§  Conocimientos que debo mostrar

| Ãrea                      | QuÃ© mostrar                                                                                                                   |
| ------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| **Deep Learning**         | Conozco arquitecturas para detecciÃ³n/segmentaciÃ³n ([[001 - 0212 Redes Neuronales Convolucionales\|CNN]], [[DETR]], [[CLIP]]). |
| **Scene Graphs**          | Entiendo cÃ³mo representar objetos y relaciones en forma de grafo.                                                             |
| **Knowledge Graphs (KG)** | SÃ© cÃ³mo modelar conocimiento explÃ­cito (conceptos, relaciones, ontologÃ­as).                                                   |
| **IntegraciÃ³n NeSy**      | SÃ© que puede ser superficial (post-hoc) o profunda (en el entrenamiento).                                                     |
| **Explicabilidad**        | Comprendo diferencia entre explicabilidad visual y simbÃ³lica.                                                                 |
| **EvaluaciÃ³n**            | Mido precisiÃ³n y tambiÃ©n coherencia o consistencia lÃ³gica.                                                                    |

---
## ğŸ§© QuÃ© es [[X-NeSyL]]

**[[X-NeSyL]] (eXplainable Neuro-Symbolic Learning)**  
MetodologÃ­a desarrollada por Siham Tabik et al.  
Combina **DL + conocimiento simbÃ³lico** para generar modelos **explicables y verificables**.
### Enfoque
1. **Integrar conocimiento experto (KG)** dentro o junto al modelo neuronal.  
2. **Explicar predicciones** con reglas y relaciones del KG.  
3. **Evaluar alineaciÃ³n explicativa** entre lo que â€œpiensaâ€ el modelo y lo que â€œsabeâ€ el experto.
### AplicaciÃ³n: MonuMAI
- ClasificaciÃ³n de fachadas monumentales.  
- IntegraciÃ³n de reglas arquitectÃ³nicas (simbÃ³licas) con redes visuales.  
- Usa **SHAP-Backprop** para alinear explicaciones visuales con el conocimiento.

---
## ğŸ§© La parte simbÃ³lica de mi TFM

### 1. RepresentaciÃ³n
Definir un **grafo de conocimiento (KG)** con:
- Entidades (`Persona`, `Coche`, `Edificio`, `SemÃ¡foro`).  
- Relaciones vÃ¡lidas (`conduce`, `entra_en`, `parte_de`, `junto_a`).  
- Reglas lÃ³gicas sobre coherencia:

> Regla: Si A es Persona y B es Coche, la relaciÃ³n vÃ¡lida es 'conduce' o 'entra_en'.
### 2. AlineaciÃ³n semÃ¡ntica
Traducir las **predicciones del modelo neuronal** a **conceptos simbÃ³licos**.

| Label Neuronal | Nodo SimbÃ³lico |
|----------------|----------------|
| car | AutomÃ³vil |
| person | Persona |
| traffic light | SemÃ¡foro |

> Ejemplo: â€œ(person, next_to, car)â€ â†’ â€œ(Persona, junto_a, AutomÃ³vil)â€
### 3. Razonamiento y ExplicaciÃ³n
- **Verificar** coherencia (â€œUna Persona puede estar junto a un AutomÃ³vilâ€).  
- **Inferir** nuevas relaciones (â€œSi hay semÃ¡foro rojo, los coches deben estar detenidosâ€).  
- **Explicar** decisiones (â€œEs una calle porque hay coches, peatones y semÃ¡forosâ€).  
### 4. ImplementaciÃ³n prÃ¡ctica
| Nivel | Herramienta | Dificultad | Aporte |
|-------|--------------|-------------|---------|
| BÃ¡sico | Python + diccionarios | ğŸŸ¢ | VerificaciÃ³n |
| Medio | Neo4j / RDF + SPARQL | ğŸŸ  | Consultas semÃ¡nticas |
| Avanzado | OWL / Prolog / Datalog | ğŸ”´ | Razonamiento completo |

---
## ğŸ§± Esquema conceptual del sistema

Imagen â†’ Red Neuronal (DETR/[[CLIP]])  â†’ Scene Graph  â†’ Mapeo labels â†” KG  â†’ Razonamiento simbÃ³lico  â†’ ExplicaciÃ³n + EvaluaciÃ³n (coherencia, consistencia)

---
## ğŸ§© Papers Clave

### ğŸ§± [[X-NeSyL]] y MonuMAI

| Paper | AÃ±o | QuÃ© aporta |
|--------|-----|-------------|
| DÃ­az-RodrÃ­guez et al., â€œ[[X-NeSyL]] methodologyâ€ | 2021 | FusiÃ³n DL + KG + SHAP-Backprop |
| Lamas et al., â€œMonuMAI Dataset and Pipelineâ€ | 2020 | Caso prÃ¡ctico: patrimonio |
| DÃ­az-RodrÃ­guez et al., â€œ[[X-NeSyL]] (Information Fusion)â€ | 2022 | FormalizaciÃ³n del mÃ©todo |
| Lamb et al., â€œGNNs Meet NeSyâ€ | 2020 | Contexto amplio de integraciÃ³n GNN + simbÃ³lico |

---
### ğŸ” Referencias recientes (2022â€“2025)

| Paper | AÃ±o | Idea Principal |
|--------|-----|----------------|
| Khan et al., *Survey of Neurosymbolic Visual Reasoning* | 2025 | Estado del arte con scene graphs |
| DeLong et al., *Neurosymbolic AI for Reasoning over KG* | 2023 | TaxonomÃ­a de enfoques hÃ­bridos |
| Khan et al., *MuRelSGG* | 2025 | SGG neurosimbÃ³lico multimodal |
| Belmecheri et al., *Explainable Scene Understanding* | 2025 | Escenas explicables con GNN |
| Cotovio et al., *KG Alignment + NeSy* | 2023 | AlineaciÃ³n simbÃ³lica entre grafos |
| Li et al., *SGTR+* | 2024 | SGG end-to-end con Transformer |
| Theory-Driven Regularization (Scene Graphs) | 2023 | Restricciones simbÃ³licas en entrenamiento |

---
## ğŸ§  Frases Ãºtiles para la reuniÃ³n

- â€œMi idea es que la **parte simbÃ³lica** actÃºe como capa de razonamiento y explicabilidad sobre las predicciones neuronales.â€  
- â€œHe leÃ­do el paper base de [[X-NeSyL]], donde integran explicaciones SHAP con conocimiento experto. Me gustarÃ­a **investigar si un enfoque similar** podrÃ­a emplearse para representar relaciones espaciales y funcionales en escenas.â€  
- â€œCreo que la mÃ©trica de **alineaciÃ³n explicativa** podrÃ­a adaptarse para medir la coherencia entre el scene graph y el KG.â€  
- â€œMe interesa su opiniÃ³n sobre quÃ© **dominio** serÃ­a mÃ¡s adecuado para un primer prototipo (urbano, patrimonio, trÃ¡ficoâ€¦).â€  
- â€œMe gustarÃ­a conocer **si existe alguna bibliografÃ­a o recursos** de _[[X-NeSyL]]_ o _MonuMAI_ que puedan servirme de referencia para orientar el marco metodolÃ³gico del trabajo.â€

---
## ğŸ“© Seguimiento tras la reuniÃ³n

1. Agradecer su tiempo.  
2. Resumir acuerdos (tutorizaciÃ³n, lecturas, prÃ³ximos pasos).  
3. Organizar un plan inicial (lectura, dataset, dominio).  

> âœ‰ï¸ â€œGracias por su tiempo. Resumo brevemente los puntos tratados: â€¦â€

---
## âœ… Checklist final

- [ ] Tener PDF del proyecto abierto.  
- [ ] Conocer 2â€“3 papers de [[X-NeSyL]] y MonuMAI.  
- [ ] Saber explicar quÃ© es la parte simbÃ³lica.  
- [ ] Mostrar claridad conceptual en la integraciÃ³n DL + KG.  
- [ ] Preparar 2â€“3 preguntas tÃ©cnicas abiertas.  
- [ ] Mostrar disposiciÃ³n a aprender de su enfoque. 
- [ ] Preguntar si puedo asistir a alguna clase suya.
---

