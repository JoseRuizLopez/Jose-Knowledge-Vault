
[[Parte Simbolica]]
# üß† Gu√≠a para la Reuni√≥n con Siham Tabik (TFM Neuro-Simb√≥lico)

**Autor:** Jos√© Ruiz L√≥pez  
**M√°ster:** DATCOM UGR (modalidad parcial)  
**Propuesta de TFM:**  
> *Modelos neurosimb√≥licos para el reconocimiento sem√°ntico de escenas mediante integraci√≥n de grafos de conocimiento y redes neuronales profundas.*

---
## üéØ Objetivo de la reuni√≥n

1. Confirmar si Siham Tabik puede ser tutora del TFM.  
2. Validar el **alcance t√©cnico** y **dominio** del proyecto.  
3. Alinear la propuesta con el enfoque de su grupo **[[X-NeSyL]]**.  
4. Obtener **orientaci√≥n bibliogr√°fica y metodol√≥gica**.  

---
## üß≠ Estructura sugerida (20‚Äì30 min)

### 1. Introducci√≥n breve (2‚Äì3 min)
> ‚ÄúGracias por su tiempo.  
> Me interesa trabajar en la intersecci√≥n entre visi√≥n por computador, conocimiento simb√≥lico y explicabilidad.  
> Creo que su enfoque en [[X-NeSyL]] es ideal para aprender a integrar conocimiento estructurado con aprendizaje profundo.‚Äù

---
### 2. Presentaci√≥n de la propuesta (5 min)

#### üß© Idea general
Ir m√°s all√° de la detecci√≥n de objetos, buscando **interpretar escenas completas** mediante la integraci√≥n:
- *Deep Learning (DL)* ‚Üí percepci√≥n visual.  
- *Knowledge Graphs (KG)* ‚Üí razonamiento simb√≥lico.  

#### ‚öôÔ∏è Enfoque t√©cnico
1. **Extracci√≥n de scene graphs** desde la imagen.  
2. **Alineaci√≥n con un KG** de dominio.  
3. **Razonamiento simb√≥lico** (verificaci√≥n, inferencia, explicabilidad).  

#### üí° Valor a√±adido
- Explicaciones estructuradas (‚Äúpor qu√© ve lo que ve‚Äù).  
- Evaluaci√≥n de consistencia l√≥gica.  
- IA m√°s confiable y transparente.

---
### 3. Preguntas clave para discutir (10‚Äì15 min)
1. ¬øQu√© dominio recomienda usar (tr√°fico, urbano, patrimonio)?  
2. ¬øConviene centrarse en toda la integraci√≥n DL+KG+razonamiento o empezar con una parte (p. ej. alineaci√≥n)?  
3. ¬øQu√© m√©tricas considera m√°s adecuadas para medir explicabilidad simb√≥lica?  
4. ¬øCree posible adaptar la metodolog√≠a **[[X-NeSyL]]** al reconocimiento de relaciones espaciales o funcionales?

---
### 4. Cuestiones pr√°cticas (5 min)
- Acceso a datasets o frameworks de **MonuMAI / [[X-NeSyL]]**.  
- Bibliograf√≠a o papers recomendados.  
- Calendario sugerido si empiezo este a√±o.  
- Posibilidad de asistir como oyente a alguna clase/seminario.

---
## üß† Conocimientos que debo mostrar

| √Årea                      | Qu√© mostrar                                                                                                                   |
| ------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| **Deep Learning**         | Conozco arquitecturas para detecci√≥n/segmentaci√≥n ([[001 - 0212 Redes Neuronales Convolucionales\|CNN]], [[DETR]], [[CLIP]]). |
| **Scene Graphs**          | Entiendo c√≥mo representar objetos y relaciones en forma de grafo.                                                             |
| **Knowledge Graphs (KG)** | S√© c√≥mo modelar conocimiento expl√≠cito (conceptos, relaciones, ontolog√≠as).                                                   |
| **Integraci√≥n NeSy**      | S√© que puede ser superficial (post-hoc) o profunda (en el entrenamiento).                                                     |
| **Explicabilidad**        | Comprendo diferencia entre explicabilidad visual y simb√≥lica.                                                                 |
| **Evaluaci√≥n**            | Mido precisi√≥n y tambi√©n coherencia o consistencia l√≥gica.                                                                    |

---
## üß© Qu√© es [[X-NeSyL]]

**[[X-NeSyL]] (eXplainable Neuro-Symbolic Learning)**  
Metodolog√≠a desarrollada por Siham Tabik et al.  
Combina **DL + conocimiento simb√≥lico** para generar modelos **explicables y verificables**.
### Enfoque
1. **Integrar conocimiento experto (KG)** dentro o junto al modelo neuronal.  
2. **Explicar predicciones** con reglas y relaciones del KG.  
3. **Evaluar alineaci√≥n explicativa** entre lo que ‚Äúpiensa‚Äù el modelo y lo que ‚Äúsabe‚Äù el experto.
### Aplicaci√≥n: MonuMAI
- Clasificaci√≥n de fachadas monumentales.  
- Integraci√≥n de reglas arquitect√≥nicas (simb√≥licas) con redes visuales.  
- Usa **SHAP-Backprop** para alinear explicaciones visuales con el conocimiento.

---
## üß© La parte simb√≥lica de mi TFM

### 1. Representaci√≥n
Definir un **grafo de conocimiento (KG)** con:
- Entidades (`Persona`, `Coche`, `Edificio`, `Sem√°foro`).  
- Relaciones v√°lidas (`conduce`, `entra_en`, `parte_de`, `junto_a`).  
- Reglas l√≥gicas sobre coherencia:

> Regla: Si A es Persona y B es Coche, la relaci√≥n v√°lida es 'conduce' o 'entra_en'.
### 2. Alineaci√≥n sem√°ntica
Traducir las **predicciones del modelo neuronal** a **conceptos simb√≥licos**.

| Label Neuronal | Nodo Simb√≥lico |
|----------------|----------------|
| car | Autom√≥vil |
| person | Persona |
| traffic light | Sem√°foro |

> Ejemplo: ‚Äú(person, next_to, car)‚Äù ‚Üí ‚Äú(Persona, junto_a, Autom√≥vil)‚Äù
### 3. Razonamiento y Explicaci√≥n
- **Verificar** coherencia (‚ÄúUna Persona puede estar junto a un Autom√≥vil‚Äù).  
- **Inferir** nuevas relaciones (‚ÄúSi hay sem√°foro rojo, los coches deben estar detenidos‚Äù).  
- **Explicar** decisiones (‚ÄúEs una calle porque hay coches, peatones y sem√°foros‚Äù).  
### 4. Implementaci√≥n pr√°ctica
| Nivel | Herramienta | Dificultad | Aporte |
|-------|--------------|-------------|---------|
| B√°sico | Python + diccionarios | üü¢ | Verificaci√≥n |
| Medio | Neo4j / RDF + SPARQL | üü† | Consultas sem√°nticas |
| Avanzado | OWL / Prolog / Datalog | üî¥ | Razonamiento completo |

---
## üß± Esquema conceptual del sistema

Imagen ‚Üí Red Neuronal (DETR/[[CLIP]])  ‚Üí Scene Graph  ‚Üí Mapeo labels ‚Üî KG  ‚Üí Razonamiento simb√≥lico  ‚Üí Explicaci√≥n + Evaluaci√≥n (coherencia, consistencia)

---
## üß© Papers Clave

### üß± [[X-NeSyL]] y MonuMAI

| Paper | A√±o | Qu√© aporta |
|--------|-----|-------------|
| D√≠az-Rodr√≠guez et al., ‚Äú[[X-NeSyL]] methodology‚Äù | 2021 | Fusi√≥n DL + KG + SHAP-Backprop |
| Lamas et al., ‚ÄúMonuMAI Dataset and Pipeline‚Äù | 2020 | Caso pr√°ctico: patrimonio |
| D√≠az-Rodr√≠guez et al., ‚Äú[[X-NeSyL]] (Information Fusion)‚Äù | 2022 | Formalizaci√≥n del m√©todo |
| Lamb et al., ‚ÄúGNNs Meet NeSy‚Äù | 2020 | Contexto amplio de integraci√≥n GNN + simb√≥lico |

---
### üîç Referencias recientes (2022‚Äì2025)

| Paper | A√±o | Idea Principal |
|--------|-----|----------------|
| Khan et al., *Survey of Neurosymbolic Visual Reasoning* | 2025 | Estado del arte con scene graphs |
| DeLong et al., *Neurosymbolic AI for Reasoning over KG* | 2023 | Taxonom√≠a de enfoques h√≠bridos |
| Khan et al., *MuRelSGG* | 2025 | SGG neurosimb√≥lico multimodal |
| Belmecheri et al., *Explainable Scene Understanding* | 2025 | Escenas explicables con GNN |
| Cotovio et al., *KG Alignment + NeSy* | 2023 | Alineaci√≥n simb√≥lica entre grafos |
| Li et al., *SGTR+* | 2024 | SGG end-to-end con Transformer |
| Theory-Driven Regularization (Scene Graphs) | 2023 | Restricciones simb√≥licas en entrenamiento |

---
## üß† Frases √∫tiles para la reuni√≥n

- ‚ÄúMi idea es que la **parte simb√≥lica** act√∫e como capa de razonamiento y explicabilidad sobre las predicciones neuronales.‚Äù  
- ‚ÄúHe le√≠do el paper base de [[X-NeSyL]], donde integran explicaciones SHAP con conocimiento experto. Me gustar√≠a **investigar si un enfoque similar** podr√≠a emplearse para representar relaciones espaciales y funcionales en escenas.‚Äù  
- ‚ÄúCreo que la m√©trica de **alineaci√≥n explicativa** podr√≠a adaptarse para medir la coherencia entre el scene graph y el KG.‚Äù  
- ‚ÄúMe interesa su opini√≥n sobre qu√© **dominio** ser√≠a m√°s adecuado para un primer prototipo (urbano, patrimonio, tr√°fico‚Ä¶).‚Äù  
- ‚ÄúMe gustar√≠a conocer **si existe alguna bibliograf√≠a o recursos** de _[[X-NeSyL]]_ o _MonuMAI_ que puedan servirme de referencia para orientar el marco metodol√≥gico del trabajo.‚Äù

---
## üì© Seguimiento tras la reuni√≥n

1. Agradecer su tiempo.  
2. Resumir acuerdos (tutorizaci√≥n, lecturas, pr√≥ximos pasos).  
3. Organizar un plan inicial (lectura, dataset, dominio).  

> ‚úâÔ∏è ‚ÄúGracias por su tiempo. Resumo brevemente los puntos tratados: ‚Ä¶‚Äù

---
## ‚úÖ Checklist final

- [x] Tener PDF del proyecto abierto.  
- [x] Conocer 2‚Äì3 papers de [[X-NeSyL]] y MonuMAI.  
- [x] Saber explicar qu√© es la parte simb√≥lica.  
- [x] Mostrar claridad conceptual en la integraci√≥n DL + KG.  
- [ ] Preparar 2‚Äì3 preguntas t√©cnicas abiertas.  
- [x] Mostrar disposici√≥n a aprender de su enfoque. 
- [ ] Preguntar si puedo asistir a alguna clase suya.
---


# Apuntes de la Reuni√≥n
Podemos usar LlaVa,

Les interesa publicar
Usar algo mas actualizado como transformer o GPTs.

No funcionan bien el ChatGPT para clarificarlo con las descripciones de las im√°genes.
Se podr√≠a centrar en las interacciones de los humanos con el entorno.
Se puede probar que cuando falla, con la explicaci√≥n del fallo aprenda a clarificarlo bien.

Podemos usar varios Llama que uno aprendido la gastronom√≠a espa√±ola y otro no, si podemos detectar si olvida conocimiento. Para detectar tambi√©n si podemos detectas si se ha aprendido conocimiento. Pero esto se desv√≠a demasiado de la idea original, mejor ajustar primero la idea original.

# Tareas
- revisar bases de datos actuales/est√°ndares para modelos simb√≥licos.
- hacer revisi√≥n bibliogr√°fica del campo, modelos, evoluci√≥n de los modelos, y por donde van,
- determinar por donde tiramos, una soluci√≥n concreta y las mejoramos o cogemos varios.
- que modelos coger
- mejorar un modelo o que?
- Modelos Nesy o Lenguaje-visi√≥n.

- Hay benchmark dentro de Nesy: Para ver que eval√∫an o que podemos echar en falta, y ver alg√∫n estado del arte y poder mejorarlo.
- Explicabilidad esos modelos.
- Cubick de Natalia Diaz, sobre los sesgos usando embeddings.
https://ieeexplore.ieee.org/abstract/document/9991965
https://openaccess.thecvf.com/content/WACV2024/papers/Koch_SGRec3D_Self-Supervised_3D_Scene_Graph_Learning_via_Object-Level_Scene_Reconstruction_WACV_2024_paper.pdf