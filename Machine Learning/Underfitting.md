links: [[001 - 020 Machine Learning|Machine Learning]]

# Underfitting
El subajuste (underfitting) ocurre cuando el modelo es demasiado simple y no logra capturar patrones importantes.

## 游댌 C칩mo prevenirlo
Dado que el underfitting se puede detectar a partir del conjunto de entrenamiento, es m치s 칰til establecer la relaci칩n dominante entre las variables de entrada y salida al principio. Si se logra mantener una complejidad de modelo adecuada, se puede evitar el subajuste y se pueden realizar predicciones m치s precisas. A continuaci칩n, se describen algunas t칠cnicas que pueden servir para reducir el subajuste:

### Disminuir la regularizaci칩n
La regularizaci칩n se suele utilizar para reducir la [[Varianza]] con un modelo aplicando una penalizaci칩n a los par치metros de entrada con los coeficientes m치s grandes. Existen varios m칠todos de regularizaci칩n, como la regularizaci칩n L1, la regularizaci칩n de Lasso, el descarte, etc. que ayudan a reducir el ruido y los valores at칤picos dentro de un modelo. Sin embargo, si las funciones de datos se vuelven demasiado uniformes, el modelo no puede identificar la tendencia dominante, y se origina el subajuste. Al disminuir la cantidad de regularizaci칩n, se introduce m치s complejidad y variaci칩n en el modelo, lo que permite un correcto entrenamiento del mismo.

### Aumentar la duraci칩n del entrenamiento
Como se ha mencionado previamente, detener el entrenamiento demasiado pronto tambi칠n puede originar un modelo underfitted. Por lo tanto, podemos evitarlo ampliando la duraci칩n del entrenamiento. Sin embargo, es importante reconocer el sobreentrenamiento y, por consiguiente, el sobreajuste. La clave est치 en encontrar el equilibrio adecuado entre los dos casos.

### Selecci칩n de funciones
Con cualquier modelo, se utilizan funciones espec칤ficas para determinar un resultado determinado. Si no hay presencia suficiente de funciones predictivas, se deben introducir m치s funciones o funciones con mayor importancia. Por ejemplo, en una red neuronal se a침adir칤an m치s neuronas ocultas, y en un bosque aleatorio se a침adir칤an m치s 치rboles. Este proceso inyecta m치s complejidad en el modelo y permite obtener mejores resultados de entrenamiento.


---
tags:
	#Concept #MachineLearning 