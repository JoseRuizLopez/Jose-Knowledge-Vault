links: [[001 - 020 Machine Learning|Machine Learning]]


# Lazy Learning

**Lazy Learning** (Aprendizaje Perezoso), tambi√©n conocido como **aprendizaje basado en instancias**, es un paradigma de [[001 - 020 Machine Learning|Machine Learning]] en el que el algoritmo **pospone la mayor parte del c√≥mputo** hasta el momento de la predicci√≥n.

A diferencia de otros m√©todos, un algoritmo _lazy_ **no construye un modelo generalizado** durante la fase de entrenamiento. En su lugar, simplemente **almacena todas las instancias** del conjunto de datos de entrenamiento.

El "aprendizaje" real ocurre cuando se presenta una nueva consulta (un nuevo punto de datos a predecir). En ese momento, el algoritmo utiliza los datos almacenados para realizar la predicci√≥n.

## üìå Eager Learning vs. Lazy Learning

La forma m√°s f√°cil de entender el _Lazy Learning_ es compararlo con su opuesto, _Eager Learning_ (Aprendizaje Ansioso):

|**Caracter√≠stica**|**Lazy Learning (Perezoso)**|**Eager Learning (Ansioso)**|
|---|---|---|
|**Fase de Entrenamiento**|R√°pida. Solo almacena los datos.|Lenta. Construye un modelo (ej. [[Backpropagation]]).|
|**Fase de Predicci√≥n**|Lenta. Realiza todo el c√°lculo al recibir una consulta.|R√°pida. Solo aplica la funci√≥n del modelo aprendido.|
|**Modelo**|No hay un modelo expl√≠cito; se basa en instancias.|Se genera un modelo o funci√≥n generalizada.|
|**Ejemplos**|**[[K-Nearest Neighbors (KNN)|KNN]]**|

---

## ‚úÖ Ventajas y ‚ùå Desventajas

### Ventajas

- **Adaptabilidad**: Es muy f√°cil a√±adir nuevos datos al "modelo", ya que solo implica a√±adirlos al conjunto de datos almacenado.
    
- **Captura de complejidad local**: Puede modelar fronteras de decisi√≥n muy complejas y espec√≠ficas, ya que se basa en los vecinos locales.
    
- **Sin tiempo de entrenamiento**: La fase de "entrenamiento" es pr√°cticamente instant√°nea.
    

### Desventajas

- **Predicci√≥n lenta**: Es computacionalmente costoso en el momento de la predicci√≥n, ya que debe comparar la nueva consulta con todos los puntos de entrenamiento.
    
- **Alto coste de almacenamiento**: Requiere almacenar todo el conjunto de datos de entrenamiento en memoria.
    
- **Sensibilidad al escalado**: Al igual que [[K-Nearest Neighbors (KNN)|KNN]], es muy sensible a la escala de las caracter√≠sticas y a la "maldici√≥n de la dimensionalidad".
    

---

## Ejemplo principal: [[K-Nearest Neighbors (KNN)|KNN]]

El ejemplo por excelencia de _Lazy Learning_ es el algoritmo **[[K-Nearest Neighbors (KNN)|K-Nearest Neighbors (KNN)]]**.

KNN no "aprende" nada durante el entrenamiento; simplemente guarda todos los puntos. Cuando llega un nuevo punto, KNN calcula la distancia a todos los puntos guardados, encuentra los K m√°s cercanos y realiza una votaci√≥n (en clasificaci√≥n) o un promedio (en regresi√≥n) para generar la predicci√≥n. Todo el trabajo se hace "perezosamente" en el momento de la consulta.

---

tags:

#Concept #MachineLearning #Algoritmo