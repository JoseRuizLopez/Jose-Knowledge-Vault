## Parte simb√≥lica en un modelo neurosimb√≥lico

En general, el componente simb√≥lico:
- **Representa conocimiento expl√≠cito** (conceptos, relaciones, reglas l√≥gicas).
- **Permite razonar o verificar consistencia** de las predicciones neuronales.
- **Act√∫a como gu√≠a o regulador** del aprendizaje profundo.

Es decir, es **todo lo que no se aprende directamente de los datos**, sino que viene de **estructura conceptual o conocimiento experto**.  
En tu caso, eso incluye desde un **grafo de conocimiento (KG)** hasta un **sistema de reglas o restricciones** sobre c√≥mo deber√≠an comportarse los objetos y sus relaciones en una escena.

---

## Niveles de la parte simb√≥lica

### üîπ Nivel 1 ‚Äî _Representaci√≥n simb√≥lica del conocimiento_
Aqu√≠ se define **qu√© sabes del mundo**, y lo formalizas. 

El DL detecta objetos y relaciones, pero se define un **grafo de conocimiento (KG)** que describe:
- Qu√© entidades existen (`Persona`, `Coche`, `Edificio`, `Sem√°foro`...)
- Qu√© relaciones son posibles (`est√°_cerca_de`, `conduce`, `entra_en`, `parte_de`...)
- Qu√© tipos de relaciones no son v√°lidas (`Persona dentro de Coche` s√≠, pero `Coche dentro de Persona` no).

üîß Ejemplo:
`Regla 1: "Si un objeto es Persona y otro es Coche, la relaci√≥n v√°lida es 'conduce' o 'entra_en', pero no 'parte_de'." Regla 2: "Si un objeto es Edificio, puede tener relaci√≥n 'parte_de' con Ciudad."`

üìò T√©cnicamente, esto se puede almacenar como:
- Un **ontolog√≠a OWL/RDF** (para razonamiento l√≥gico formal).
- Un **Neo4j graph** (si priorizas consultas estructuradas).
- Un **diccionario Python + reglas simb√≥licas** (m√°s simple, pero suficiente para un prototipo).

---

### üîπ Nivel 2 ‚Äî _Alineaci√≥n sem√°ntica entre DL y KG_
La red neuronal detecta ‚Äúcosas‚Äù (perros, coches, sem√°foros...), pero **esas detecciones deben alinearse con conceptos simb√≥licos** del KG.

Esto implica:
1. Crear un **mapeo entre labels neuronales** (provenientes del dataset visual) **y nodos del grafo simb√≥lico**. 
> ¬øSe deber√≠a usar un embeding sem√°ntico/tabla de equivalencias para alinear autom√°ticamente t√©rminos similares para resolver la ambig√ºedad posible en el mapeo??
2. Traducir las salidas de la red (por ejemplo, tripletas ‚ÄúPersona ‚Äì junto_a ‚Äì Coche‚Äù) a nodos y aristas en un grafo sem√°ntico.
3. Verificar si esas relaciones **tienen sentido seg√∫n el conocimiento simb√≥lico**.

üîß Ejemplo:
> El modelo detecta ‚ÄúCoche sobre Persona‚Äù ‚Üí la parte simb√≥lica verifica que **esa relaci√≥n no es coherente** ‚Üí puede marcarla como inconsistente o corregirla.

üìò Aqu√≠ entra el razonamiento simb√≥lico:  
usando l√≥gicas tipo **Datalog, Prolog, OWL Reasoner** o incluso comprobaciones heur√≠sticas, puedes **detectar contradicciones o anomal√≠as**.

---
### üîπ Nivel 3 ‚Äî _Razonamiento y explicabilidad simb√≥lica_
El paso final es **usar ese conocimiento simb√≥lico para razonar o explicar**.

Esto puede adoptar tres formas:
#### (a) Verificaci√≥n / consistencia
Compruebas si las relaciones detectadas son v√°lidas:

> ‚ÄúEl sistema detect√≥ una persona conduciendo un coche, lo cual es coherente con las reglas del conocimiento.‚Äù
#### (b) Inferencia / enriquecimiento
Generas nuevas relaciones a partir del conocimiento:

> ‚ÄúSi un objeto es sem√°foro y est√° en rojo, infiero que los coches cercanos deber√≠an estar detenidos.‚Äù
#### (c) Explicaci√≥n
Usas el grafo simb√≥lico para **justificar** lo que el modelo visual predijo:

> ‚ÄúClasifiqu√© esto como una calle porque hay coches, peatones y sem√°foros alineados.‚Äù
---
## üß© 3. C√≥mo interact√∫an parte neuronal y simb√≥lica
Piensa en tu sistema como **dos cerebros colaborando**:

| Parte                       | Funci√≥n      | Ejemplo                                                                |
| --------------------------- | ------------ | ---------------------------------------------------------------------- |
| **Neuronal (DL)**           | Percepci√≥n   | ‚ÄúVeo un coche, una persona y un sem√°foro.‚Äù                             |
| **Simb√≥lica (KG + reglas)** | Razonamiento | ‚ÄúUn coche y una persona pueden estar juntos si la persona lo conduce.‚Äù |
| **Neuro-simb√≥lica**         | Integraci√≥n  | Ajusta predicciones seg√∫n conocimiento, o explica resultados.          |

üìò Puedes visualizarlo como un pipeline:
`Imagen ‚Üí CNN/Transformer (detector) ‚Üí Scene Graph ‚Üí Alineaci√≥n con KG ‚Üí Razonamiento simb√≥lico`

La parte simb√≥lica empieza **a partir del Scene Graph**, y es la que le da **sentido sem√°ntico y explicabilidad estructural**.

---
## ‚öôÔ∏è 4. C√≥mo implementarlo (opciones pr√°cticas)

Dependiendo del enfoque y tiempo que tengas, hay varios niveles de profundidad:

| Nivel    | Herramienta / Enfoque                       | Dificultad | Qu√© aporta                                           |
| -------- | ------------------------------------------- | ---------- | ---------------------------------------------------- |
| B√°sico   | Diccionario + comprobaci√≥n l√≥gica en Python | üü¢F√°cil    | Verificaci√≥n b√°sica de relaciones v√°lidas            |
| Medio    | Neo4j o RDF + SPARQL                        | üü†Media    | Consultas estructuradas y reglas declarativas        |
| Avanzado | OWL Reasoner / Prolog / Datalog             | üî¥Alta     | Razonamiento l√≥gico complejo e inferencia autom√°tica |

---
## üß≠ 5. C√≥mo explic√°rselo a Siham Tabik

Puedes decir algo como:

> ‚ÄúLa parte simb√≥lica de mi TFM ser√° el m√≥dulo que represente y razone sobre el conocimiento. Mi idea es dise√±ar un grafo de conocimiento con las entidades y relaciones v√°lidas entre objetos de la escena.  
> Este grafo servir√° tanto para verificar la coherencia de las relaciones detectadas por el modelo visual como para generar explicaciones estructuradas del tipo ‚Äòpor qu√© se ha clasificado as√≠‚Äô.  
> Adem√°s, me gustar√≠a estudiar c√≥mo integrar parte de ese conocimiento como restricciones suaves durante el entrenamiento, siguiendo la l√≠nea de [[X-NeSyL]].‚Äù

Eso conecta directamente con su marco y con los papers que revisamos (EXPLANet, SHAP-Backprop, Semantic Loss...).

---
## üß± 6. En resumen

|Rol|Qu√© hace la parte simb√≥lica|
|---|---|
|**Representar**|Define un modelo conceptual del mundo (KG, reglas, ontolog√≠a)|
|**Verificar**|Comprueba que las predicciones neuronales sean coherentes|
|**Inferir**|Deduce relaciones adicionales basadas en reglas|
|**Explicar**|Justifica decisiones con conocimiento expl√≠cito|
|**Guiar**|(Opcional) Aporta restricciones o feedback al entrenamiento|



Podemos usar LlaVa,

Les interesa publicar
Usar algo mas actualizado como transformer o gpts.

No funcionan bien el ChatGPT para clasificarlo con las descripciones de las im√°genes.
Se podr√≠a centrar en las interacciones de los humanos con el entorno.
Se puede probar que cuando falla, con la explicaci√≥n del fallo aprenda a clasificarlo bien.

Podemos usar varios Llama que uno aprendido la gastronom√≠a espa√±ola y otro no, si podemos detectar si olvida conocimiento. Para detectar tambi√©n si podemos detectas si se ha aprendido conocimiento.

# Tareas
- revisar bases de datos actuales/est√°ndares para modelos simb√≥licos.
- hacer revision bibliografica del campo, modelos, evolucion de los modelos, y por donde van,
- determinar por donde tiramos, una solucion concreta y las mejoramos o cogemos varios.
- que modelos coger
- mejorar un modelo o que?
- Modelos Nesi o Lenguaje-visi√≥n.

- Hay benchmark dentro de Nesi: Para ver que eval√∫an o que podemos echar en falta, y ver alg√∫n estado del arte y poder mejorarlo.
- Explicabilidad esos modelos.
- Cubick de Natalia Diaz, sobre los sesgos usando embeddings.
https://ieeexplore.ieee.org/abstract/document/9991965
https://openaccess.thecvf.com/content/WACV2024/papers/Koch_SGRec3D_Self-Supervised_3D_Scene_Graph_Learning_via_Object-Level_Scene_Reconstruction_WACV_2024_paper.pdf
