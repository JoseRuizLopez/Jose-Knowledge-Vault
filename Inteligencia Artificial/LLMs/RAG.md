links: [[001 - 020 Inteligencia Artificial|Inteligencia Artificial]]

# Retrieval-Augmented Generation (RAG)

## ğŸ§© Â¿QuÃ© es RAG?
**Retrieval-Augmented Generation (RAG)** es una tÃ©cnica avanzada en el campo de la inteligencia artificial y procesamiento del lenguaje natural (NLP) que permite a los modelos de lenguaje acceder a informaciÃ³n externa antes de generar una respuesta. A diferencia de los modelos generativos tradicionales que responden Ãºnicamente con base en lo que aprendieron durante su entrenamiento, **RAG combina generaciÃ³n de texto con bÃºsqueda de informaciÃ³n**, lo que lo hace mÃ¡s preciso, flexible y verificable.

  

### âœ¨ MotivaciÃ³n
Los modelos de lenguaje grandes (LLMs) como GPT, BERT, T5 o BART tienen un conocimiento fijo: una vez entrenados, no pueden aprender nueva informaciÃ³n a menos que se reentrenen. Esto representa una limitaciÃ³n en contextos donde:

- Se necesita informaciÃ³n actualizada.
- Se requiere conocimiento especÃ­fico o privado.
- Es importante la trazabilidad de la respuesta.

RAG soluciona este problema permitiendo que el modelo **busque activamente informaciÃ³n relevante en una base externa** (por ejemplo, una colecciÃ³n de documentos, bases de datos, APIs o Wikipedia) antes de generar la respuesta.

## âš™ï¸ Â¿CÃ³mo funciona RAG?
Un sistema RAG consta de dos mÃ³dulos principales:

### 1. **Retriever (recuperador)**
- Toma la pregunta del usuario y la convierte en una consulta.
- Busca documentos relevantes en una base de conocimiento.
- TÃ©cnicas comunes: bÃºsqueda semÃ¡ntica con embeddings, BM25, bÃºsqueda hÃ­brida.

### 2. **Generator (generador)**
- Recibe la pregunta original + documentos recuperados.
- Genera una respuesta en lenguaje natural, fundamentada en esos documentos.

### ğŸ”„ Flujo completo
![[rag.png]]

## âœ… Ventajas clave

| Ventaja Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | DescripciÃ³n |
|----------------------------------|-------------|
| **ActualizaciÃ³n sin reentrenar** | Basta con actualizar los documentos, no el modelo. |
| **Conocimiento personalizado** | Puede trabajar con datos de una empresa, proyecto o persona. |
| **Mayor precisiÃ³n factual** Â  | Reduce alucinaciones, se basa en hechos reales. |
| **Verificabilidad** Â  Â  Â  Â  Â  | Permite mostrar las fuentes utilizadas. |
| **MÃ¡s eficiente** Â  Â  Â  Â  Â  Â  | No necesitas entrenar modelos gigantes si tienes buenos datos. |

## âš ï¸ Limitaciones y desafÃ­os
- **Dependencia del recuperador**: si los documentos recuperados no son relevantes, la respuesta tampoco lo serÃ¡.
- **Sin razonamiento multihop**: no encadena mÃºltiples bÃºsquedas por sÃ­ solo.
- **Infraestructura compleja**: requiere componentes adicionales (vector stores, embeddings, pipelines).
- **Calidad de la base de datos**: necesita una base bien estructurada, fragmentada y mantenida.
- **Privacidad y seguridad**: si se trabaja con datos sensibles, se debe evitar enviar documentos a APIs externas.

## ğŸ’¼ Casos de uso

### ğŸ§‘â€ğŸ’¼ Empresas
- Chatbots de soporte que responden con base en FAQs o manuales internos.
- Asistentes legales o financieros que consultan bases documentales internas.
- GeneraciÃ³n de informes ejecutivos con datos actualizados y especÃ­ficos.

### ğŸ“ EducaciÃ³n e investigaciÃ³n
- Tutores inteligentes que responden usando libros de texto o papers.
- Asistentes para redactar trabajos acadÃ©micos con referencias reales.

### ğŸ‘¨â€ğŸ’» Desarrollo y documentaciÃ³n tÃ©cnica
- Respuestas basadas en documentaciÃ³n de APIs.
- GeneraciÃ³n de ejemplos o cÃ³digo usando la base documental del proyecto.

### ğŸ§  Productividad personal
- BÃºsqueda de informaciÃ³n en notas propias, emails o archivos PDF.
- Resumen de mÃºltiples documentos en lenguaje natural.

## ğŸ› ï¸ TecnologÃ­as y frameworks

### Frameworks para construir sistemas RAG
- **[[Haystack]]**: Orientado a bÃºsqueda y QA; muy usado en entornos empresariales.
- **[[LangChain]]**: ComposiciÃ³n de cadenas y agentes con LLMs + recuperaciÃ³n.
- **[[LlamaIndex]]**: Ideal para conectar documentos con un modelo LLM.

### Bases vectoriales
- **[[FAISS]]**: RÃ¡pido, ideal para desarrollo local.
- **[[Pinecone]]**, **Weaviate**, **Qdrant**: Escalables, con APIs modernas y funcionalidades avanzadas.
- **[[ElasticSearch]] (con plugin vectorial)**: CombinaciÃ³n de bÃºsqueda lexical y semÃ¡ntica.

### Generadores y embeddings
- **GPT-4**, **GPT-3.5**, **BART**, **T5**.
- **OpenAI Embeddings**, **Cohere**, **SentenceTransformers**.

## ğŸ“š Ejemplo prÃ¡ctico (simplificado)
Supongamos que un usuario pregunta:

> â€œÂ¿QuÃ© es el metaverso y quÃ© empresas estÃ¡n trabajando en ello?â€  

### RAG harÃ¡ lo siguiente:
1. El **retriever** busca en una colecciÃ³n de artÃ­culos recientes o documentaciÃ³n empresarial.
2. Encuentra 5 fragmentos donde se habla de Meta, Microsoft y NVIDIA trabajando en el metaverso.
3. El **generador** recibe esos textos junto con la pregunta.
4. Produce una respuesta como:

> â€œEl metaverso es un entorno virtual inmersivo. Empresas como Meta, Microsoft y NVIDIA estÃ¡n desarrollando tecnologÃ­as para soportarlo, desde realidad virtual hasta plataformas 3D colaborativas.â€


---
tags:
	#Concept  #MachineLearning #RAG  

---

**ğŸ”— References**
- ğŸ“„ [Paper original â€“ Lewis et al. (2020)](https://arxiv.org/abs/2005.11401)
- ğŸ§  [Haystack](https://docs.haystack.deepset.ai/)
- ğŸ”— [LangChain](https://docs.langchain.com/)
- ğŸ“‚ [LlamaIndex](https://docs.llamaindex.ai/)
- ğŸ§¾ [Azure + OpenAI + RAG](https://learn.microsoft.com/en-us/azure/architecture/example-scenario/ai/retrieval-augmented-generation)
- ğŸ§ª [Blog IBM sobre RAG](https://research.ibm.com/blog/retrieval-augmented-generation-rag)


[^1]: https://research.ibm.com/blog/retrieval-augmented-generation-RAG#:~:text=RAG%20is%20an%20AI%20framework,insight%20into%20LLMs%27%20generative%20process
	

[^2]: https://js.langchain.com/docs/concepts/rag/#:~:text=Retrieval%20Augmented%20Generation%20,powerful%20technique%20for%20building%20more
	

[^3]: https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview#:~:text=Retrieval%20Augmented%20Generation%20,embedding%20models%20for%20that%20content
	

[^4]: https://qdrant.tech/articles/what-is-rag-in-ai/
	

[^5]: https://qdrant.tech/articles/what-is-rag-in-ai/#:~:text=RAG%20architecture
	

[^6]: https://qdrant.tech/articles/what-is-rag-in-ai/#:~:text=With%20the%20top%20relevant%20passages,that%20information%20in%20natural%20language
	

[^7]: https://qdrant.tech/articles/what-is-rag-in-ai/#:~:text=RAG%20architecture
	

[^8]: https://qdrant.tech/articles/what-is-rag-in-ai/#:~:text=The%20Retriever
	

[^9]: https://qdrant.tech/articles/what-is-rag-in-ai/#:~:text=This%20approach%20uses%20large%20language,distance%20metrics%20like%20cosine%20similarity
	

[^10]: https://qdrant.tech/articles/what-is-rag-in-ai/#:~:text=
	

[^11]: https://qdrant.tech/articles/what-is-rag-in-ai/#:~:text=With%20the%20top%20relevant%20passages,that%20information%20in%20natural%20language
	

[^12]: https://huggingface.co/docs/transformers/model_doc/rag#:~:text=Retrieval,to%20adapt%20to%20downstream%20tasks
	

[^13]: https://arxiv.org/abs/2005.11401#:~:text=pre,only%20seq2seq
	
